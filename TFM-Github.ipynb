{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5exG6uOvsgs"
   },
   "source": [
    "# ML for metastasis\n",
    "\n",
    "ML classifiers for metastatic vs non-metastatic protein sequences.\n",
    "\n",
    "1.   Get fasta sequences and convert them into TXT (metastatic and non-metastatic proteins)\n",
    "2.   Calculate molecular descriptors (dataset for ML)\n",
    "3.   Build ML classifiers for metastatic and non-metastatic protein sequences (split dataset, build models, feature selection, model comparison)\n",
    "4. Statistical analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpM-edgfVeSF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOjyPjWYdJLv",
    "outputId": "0f91de6e-30a4-49d3-9039-8248ca5a194b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDZyZyscyBRz"
   },
   "outputs": [],
   "source": [
    "dsPath =  # set path to dataset subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kmzg6UymdsRZ",
    "outputId": "80804ad5-5d09-4802-a45b-84c62dda6bb4"
   },
   "outputs": [],
   "source": [
    "# Print content in drive to check if it is OK\n",
    "for filename in os.listdir(dsPath):\n",
    "  print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHnzS7OrbyNa"
   },
   "outputs": [],
   "source": [
    "resPath =  # set path to results subfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtZ9cc-Z9X_a"
   },
   "source": [
    "## Convert FASTA to CSV format\n",
    "\n",
    "Read all the sequences for metastatic and non-metastatic proteins and convert in ProteinName, Sequence format as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AF-xaN9eWvfB",
    "outputId": "cd92568b-e4bd-4bf6-e627-320f3cd96df5"
   },
   "outputs": [],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VX9icrY_VeSN"
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzMpDONew16P"
   },
   "outputs": [],
   "source": [
    "# Define a function to read fasta sequences one at a time\n",
    "def fasta_generator(input_file):\n",
    "    with open(input_file, 'r') as fasta_file:\n",
    "        for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "            yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmn_nTvr0fw1"
   },
   "outputs": [],
   "source": [
    "# Define 2 lists with protein name\n",
    "metastasis_POS = []  # metastatic proteins\n",
    "metastasis_NEG = []  # non-metastatic proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRKPWe_pvy1L"
   },
   "outputs": [],
   "source": [
    "# Get fasta sequences for metastasis_POS proteins\n",
    "# Define fasta file to read and csv file to write the protein name and the sequences\n",
    "inFile  = dsPath+'MODELO_1_POSITIVE_metastasis.fasta' # to read\n",
    "outFile = dsPath+'metastasis_POS.csv'       # to write\n",
    "\n",
    "# Open the output file for writing\n",
    "with open(outFile, 'w') as out_file:\n",
    "  out_file.write(f'ProteinDescription,Sequence\\n')  # write the header\n",
    "  # Iterate over each fasta sequence using the generator\n",
    "  for fasta in fasta_generator(inFile):\n",
    "      name = fasta.id\n",
    "      sequence = str(fasta.seq)               # convert the sequence to a string\n",
    "      out_file.write(f'{name},{sequence}\\n')  # write only the sequence to the output file\n",
    "      metastasis_POS.append(name+\",\"+sequence)           # add the sequence to a list TFs\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNaL6QWN0-YK",
    "outputId": "3c76a6f4-1e18-43f4-f8d6-5f96e7efc5d0"
   },
   "outputs": [],
   "source": [
    "# Checking metastasis_POS list\n",
    "print(\"No of metastasis_POS sequences:\", len(metastasis_POS))\n",
    "# Print first sequence in metastasis_POS to check if it is OK\n",
    "print(\"First metastasis_POS sequence:\\n\"+metastasis_POS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_NB8JhYybs9"
   },
   "outputs": [],
   "source": [
    "# Get fasta sequences for metastasis_NEG proteins\n",
    "# Define fasta file to read and csv file to write the protein names and sequences\n",
    "inFile  = dsPath+'MODELO_1_NEGATIVE_metastasis.fasta'\n",
    "outFile = dsPath+'metastasis_NEG.csv'\n",
    "\n",
    "# Open the output file for writing\n",
    "with open(outFile, 'w') as out_file:\n",
    "  out_file.write(f'ProteinDescription,Sequence\\n')  # write the header\n",
    "  # Iterate over each fasta sequence using the generator\n",
    "  for fasta in fasta_generator(inFile):\n",
    "      name = fasta.id\n",
    "      sequence = str(fasta.seq)               # convert the sequence to a string\n",
    "      out_file.write(f'{name},{sequence}\\n')  # write only the sequence to the output file\n",
    "      metastasis_NEG.append(name+\",\"+sequence)        # add the sequence to a list\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bMkqMvU0Vq-",
    "outputId": "a1c00585-0ef2-4e70-b30b-d287fdd46909"
   },
   "outputs": [],
   "source": [
    "# Checking metastasis_NEG list\n",
    "print(\"No of metastasis_NEG sequences:\", len(metastasis_NEG))\n",
    "# Print first sequence to check if it is OK\n",
    "print(\"First metastasis_NEG sequence:\\n\"+metastasis_NEG[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Z9xSsRT9oOv"
   },
   "source": [
    "## Check for common sequences in metastasis_POS and metastasis_NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-2_HsFz2Aj6",
    "outputId": "007ee782-365f-42e8-d0ee-06c5dfac1e0a"
   },
   "outputs": [],
   "source": [
    "# List with errors\n",
    "errors = []\n",
    "\n",
    "# Check if we have the same sequence in both lists\n",
    "with open(dsPath+\"Errors.csv\", 'w') as out_file:\n",
    "  out_file.write(f'ErrNo,metastasis_POS,metastasis_NEG,metastasis_POS_seq, metastasis_NEG_seq\\n')\n",
    "  n=0\n",
    "  for idmPOS in range(len(metastasis_POS)):\n",
    "    name_metastasis_POS, seq_metastasis_POS = metastasis_POS[idmPOS].split(',')\n",
    "    for idmNEG in range(len(metastasis_NEG)):\n",
    "      name_metastasis_NEG, seq_metastasis_NEG = metastasis_NEG[idmNEG].split(',')\n",
    "      if (name_metastasis_POS == name_metastasis_NEG):\n",
    "        n=n+1\n",
    "        print(n, name_metastasis_POS, name_metastasis_NEG, seq_metastasis_POS, seq_metastasis_NEG)\n",
    "        out_file.write(f'{n},{name_metastasis_POS},{name_metastasis_NEG},{seq_metastasis_POS},{seq_metastasis_NEG}\\n')\n",
    "        errors.append(name_metastasis_NEG+\",\"+seq_metastasis_NEG)        # add the sequence to a list\n",
    "        continue\n",
    "  if n==0: print(\"No errors!\")\n",
    "  else:\n",
    "    print(errors)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my4vKoxD9yOC"
   },
   "source": [
    "## Get the list of sequences to use for descriptors calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPW3V41NF_7N"
   },
   "outputs": [],
   "source": [
    "# Get only the lists of ONLY the sequences\n",
    "listmPOS = []\n",
    "for seqPOS in metastasis_POS:\n",
    "    name_seqPOS, seq_seqPOS = seqPOS.split(',')\n",
    "    listmPOS.append(seq_seqPOS)\n",
    "\n",
    "# Get only the lists of ONLY the sequences\n",
    "listmNEG = []\n",
    "for seqNEG in metastasis_NEG:\n",
    "    name_seqNEG, seq_seqNEG = seqNEG.split(',')\n",
    "    listmNEG.append(seq_seqNEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eJlu4tUG78O",
    "outputId": "43dcf8c2-092b-460b-ddef-4834c202d6a5"
   },
   "outputs": [],
   "source": [
    "print(\"The study will use\", len(listmPOS),\"metastasic sequences vs.\", len(listmNEG), \"non metastasic sequences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMBuSxdqI60s"
   },
   "source": [
    "## Molecular descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0q3uTsLzMG2s",
    "outputId": "d87459ff-10ba-40ae-b053-0fc1621598f4"
   },
   "outputs": [],
   "source": [
    "# Install package for protein molecular descriptors\n",
    "!pip install propy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DePTHZg-UD9l"
   },
   "outputs": [],
   "source": [
    "from propy import PyPro\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ttMkSpjtGvd"
   },
   "source": [
    "### Descriptors from list (metastasis_POS and metastasis_NEG) to dataframes (AAC, DPC, Mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJTp4_slP7v5"
   },
   "outputs": [],
   "source": [
    "def to_dataframe(list_sequences, is_POS):\n",
    "    data_AAC = []  # list with AAC descriptors\n",
    "    data_DPC = []  # list with DPC descriptors\n",
    "    data_Mix = []  # list with Mix descriptors\n",
    "\n",
    "    for sequence in list_sequences:  # for each sequence of the list\n",
    "        DesObject = PyPro.GetProDes(sequence)  # create an object for descriptors\n",
    "        amino_acid_composition = DesObject.GetAAComp()  # calculate amino_acid_composition (AAC) descriptors (dictionary)\n",
    "        dipeptide_composition = DesObject.GetDPComp()  # calculate dipeptide_composition (DPC) descriptors (dictionary)\n",
    "        data_AAC.append(list(amino_acid_composition.values()))  # add AAC descriptors to list data_AAC\n",
    "        data_DPC.append(list(dipeptide_composition.values()))  # add DPC descriptors to list data_DPC\n",
    "        data_Mix.append(list(amino_acid_composition.values()) + list(dipeptide_composition.values()))  # add both AAC and DPC descriptors (mix) to list data_Mix\n",
    "\n",
    "    # create 3 dataframes, one for each set of descriptors: AAC, DPC and Mix,\n",
    "    # using the descriptors values from the previous lists and the header with the descriptors names (dictionary keys)\n",
    "    # amino_acid_composition, dipeptide_composition are dictionaries\n",
    "    columns_AAC = list(amino_acid_composition.keys())\n",
    "    columns_DPC = list(dipeptide_composition.keys())\n",
    "\n",
    "    df_AAC = pd.DataFrame(data_AAC, columns=columns_AAC)\n",
    "    df_DPC = pd.DataFrame(data_DPC, columns=columns_DPC)\n",
    "    df_Mix = pd.DataFrame(data_Mix, columns=columns_AAC + columns_DPC)\n",
    "\n",
    "    # add a new column as the last one with the class (metastasis_POS = 1; metastasis_NEG = 0)\n",
    "    df_AAC['Class'] = 1 if is_POS else 0\n",
    "    df_DPC['Class'] = 1 if is_POS else 0\n",
    "    df_Mix['Class'] = 1 if is_POS else 0\n",
    "\n",
    "    return df_AAC, df_DPC, df_Mix\n",
    "\n",
    "# listmPOS\n",
    "df_AAC_mPOS, df_DPC_mPOS, df_Mix_mPOS = to_dataframe(listmPOS, is_POS=True)\n",
    "\n",
    "# listmNEG\n",
    "df_AAC_mNEG, df_DPC_mNEG, df_Mix_mNEG = to_dataframe(listmNEG, is_POS=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lIrPcFJR6fM"
   },
   "outputs": [],
   "source": [
    "# Checking dataframes\n",
    "\n",
    "# Metastasis_POS\n",
    "#df_AAC_mPOS\n",
    "#df_DPC_mPOS\n",
    "#df_Mix_mPOS\n",
    "\n",
    "# Metastasis_NEG\n",
    "#df_AAC_mNEG\n",
    "#df_DPC_mNEG\n",
    "#df_Mix_mNEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgUtGT6zEKjY"
   },
   "source": [
    "## Datasets\n",
    "\n",
    "We will create different datasets using the previous dataframes with descriptors for metastasis_POS and metastasis_NEG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-R8LqQd2K2g"
   },
   "source": [
    "### Datasets with all descriptors (no feature selection, without normalization)\n",
    "\n",
    "We have 6 dataframes with descriptors for metastasis_POS and metastasis_NEG:\n",
    "\n",
    "*   for metastasis_POS: df_AAC_mPOS, df_DPC_mPOS, df_Mix_mPOS\n",
    "*   for metastasis_NEG: df_AAC_mNEG, df_DPC_mNEG, df_Mix_mNEG\n",
    "\n",
    "We will mix descriptors for metastasis_POS and metastasis_NEG for each subset of descriptors: AAC, DPC and Mix (by merging the correspondent dataframes). We will obtain datasets: ds_AAC, ds_DPC, ds_Mix as dataframes and CSV files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IFRcooMaWtj"
   },
   "outputs": [],
   "source": [
    "ds_AAC = pd.concat([df_AAC_mPOS, df_AAC_mNEG], axis=0) # dataset for AAC (AAC descriptors for metastasis_POS and metastasis_NEG)\n",
    "ds_DPC = pd.concat([df_DPC_mPOS, df_DPC_mNEG], axis=0) # dataset for DPC (DPC descriptors for metastasis_POS and metastasis_NEG)\n",
    "ds_Mix = pd.concat([df_Mix_mPOS, df_Mix_mNEG], axis=0) # dataset for Mix (AAC and DPC descriptors for metastasis_POS and metastasis_NEG)\n",
    "\n",
    "# Save the datasets on files (in your Gdrive folder)\n",
    "# These are the datasets with all the descriptors, without feature selection, without data normalization!\n",
    "ds_AAC.to_csv(dsPath+'dsAAC.csv', index=False)\n",
    "ds_DPC.to_csv(dsPath+'dsDPC.csv', index=False)\n",
    "ds_Mix.to_csv(dsPath+'dsMix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTiyw8Ftb3Fh"
   },
   "outputs": [],
   "source": [
    "# Checking dataframes\n",
    "#ds_AAC\n",
    "#ds_DPC\n",
    "#ds_Mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PwIvuWV-KBG"
   },
   "source": [
    "The datasets from dsAAC.csv, dsDPC.csv and dsMix.csv will be used in feature selections and directly to build ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzijyjy3D60D"
   },
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "UDnzafkYDzIL",
    "outputId": "619cf38b-e151-433f-8726-c386f83959f7"
   },
   "outputs": [],
   "source": [
    "data = ds_DPC\n",
    "\n",
    "class_column = data.columns[-1]\n",
    "class_count = data[class_column].value_counts()\n",
    "\n",
    "plt.figure(figsize=(4, 5))\n",
    "\n",
    "class_count.plot(kind='bar', color=['#87CEEB', '#98FB98'], width=0.35)\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Amount of proteins')\n",
    "plt.title('Data Distribution')\n",
    "\n",
    "plt.xticks(ticks=[0, 1], labels=['Non-metastatic proteins', 'Metastatic proteins'], rotation=0, wrap=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59VJ1xDo_v62"
   },
   "source": [
    "### Normalized datasets of AAC, DPC and Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8MDaglD_00h"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AntFmoEeoNK"
   },
   "outputs": [],
   "source": [
    "# Normalises the datasets between 0 and 1\n",
    "\n",
    "def normalize(ds, ds_name, ds_path):\n",
    "    # create the normalized dataframe as copy of the raw dataset\n",
    "    ds_norm = ds.copy()\n",
    "\n",
    "    # create a scaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # select all columns except the last one (excluding the class)\n",
    "    cols_to_scale = ds_norm.columns[:-1]\n",
    "\n",
    "    # normalize the selected columns\n",
    "    ds_norm[cols_to_scale] = scaler.fit_transform(ds_norm[cols_to_scale])\n",
    "\n",
    "    # save the scaler for future predictions\n",
    "    scaler_file = ds_path + 'ds{}_norm_scalerMinMax.pkl'.format(ds_name)\n",
    "    joblib.dump(scaler, scaler_file)\n",
    "\n",
    "    # save the normalized dataset as CSV file\n",
    "    ds_norm.to_csv(ds_path + 'ds{}_norm.csv'.format(ds_name), index=False)\n",
    "\n",
    "    return ds_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVmuRrX0ezKi"
   },
   "outputs": [],
   "source": [
    "# AAC dataset\n",
    "ds_AAC_norm = normalize(ds_AAC, 'AAC', dsPath)\n",
    "\n",
    "# DPC dataset\n",
    "ds_DPC_norm = normalize(ds_DPC, 'DPC', dsPath)\n",
    "\n",
    "# Mix dataset\n",
    "ds_Mix_norm = normalize(ds_Mix, 'Mix', dsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "Um0Ig-jXe6sR",
    "outputId": "f3ffd1f1-c0fd-4e03-a2cf-899b15c42d57"
   },
   "outputs": [],
   "source": [
    "# Checking the normalized datasets\n",
    "#ds_AAC_norm\n",
    "#ds_DPC_norm\n",
    "#ds_Mix_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMjxzaGkHrHk"
   },
   "source": [
    "## Univariate feature selection\n",
    "\n",
    "The normalized datasets for AAC, DPC and Mix will be used to build ML models and for selection features. This moment, we have 3 datasets (normalized datasets with pool features for AAC, DPC and Mix).\n",
    "\n",
    "We will create 3 new datasets with the best features for AAC, DPC and Mix descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIOjVa5JCcWy"
   },
   "outputs": [],
   "source": [
    "# Function to obtain input descriptors and output class as arrays, and the list with the names of the descriptors\n",
    "\n",
    "def getDataFromDataFrame(df, OutVar='Class'):\n",
    "    # get X, Y data and column names from df\n",
    "    print('\\n-> Get X & Y data, Features list')\n",
    "    print('Shape', df.shape)\n",
    "\n",
    "    # select X and Y\n",
    "    ds_y = df[OutVar]\n",
    "    ds_X = df.drop(OutVar,axis = 1)\n",
    "    Xdata = ds_X.values # get values of features\n",
    "    Ydata = ds_y.values # get output values\n",
    "\n",
    "    print('Shape X data:', Xdata.shape)\n",
    "    print('Shape Y data:', Ydata.shape)\n",
    "    print('Done!')\n",
    "\n",
    "    # return data for X and Y, feature names as list\n",
    "    return (Xdata, Ydata, list(ds_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccrMfqq1KAdz"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "def FeatureSelection(df,label,nFeats=1):\n",
    "    if nFeats == 0:\n",
    "        print(\"\\n NO feature selection\")\n",
    "        return df\n",
    "\n",
    "    # Get separated info\n",
    "    Xdata, Ydata, Features = getDataFromDataFrame(df)  # out var = Class\n",
    "\n",
    "    # Feature selection\n",
    "    print('\\n-> Univariate Feature selection')\n",
    "    print('Initial columns:', list(df.columns))\n",
    "    selector= SelectKBest(f_classif, k=nFeats)  # you can select other feature selection\n",
    "    Xdata = selector.fit_transform(Xdata, Ydata)  # select the features\n",
    "\n",
    "    # Get the selected features\n",
    "    SelFeatures = []\n",
    "    for i in selector.get_support(indices=True):\n",
    "        SelFeatures.append(Features[i])\n",
    "\n",
    "    # Create the new dataframe with selected features\n",
    "    df = pd.DataFrame(Xdata,columns=SelFeatures)\n",
    "    df['Class'] = Ydata  # add class column\n",
    "    print('Final columns:', list(df.columns))\n",
    "\n",
    "    # Save selected feature dataset\n",
    "    selectFile = dsPath+'ds'+label+'.normFS('+str(nFeats)+').csv'  # dataset with selected features\n",
    "    print('* Save selected features dataset:', selectFile)\n",
    "    df.to_csv(selectFile, index=False)\n",
    "\n",
    "    print('Done!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToB2Ns3xiWaR"
   },
   "source": [
    "### 50% of descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "6UY1B8rHiaKy",
    "outputId": "8f8e405c-be55-4624-9c50-0623a27e3c19"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection for AAC using the normalized dataset\n",
    "ds_AAC_normFS50 = FeatureSelection(ds_AAC_norm,\"AAC\",nFeats=10) # select the best 10 features (10/20)\n",
    "ds_AAC_normFS50 # check the feature selected dataset for AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "6tiJIXqEimuV",
    "outputId": "04152be3-243b-425c-eedd-831906c34a69"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection for DPC using the normalized dataset\n",
    "ds_DPC_normFS50 = FeatureSelection(ds_DPC_norm,\"DPC\",nFeats=200) # select the best 200 features (200/400)\n",
    "ds_DPC_normFS50 # check the feature selected dataset for DPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "C7Q2m-IKiv-z",
    "outputId": "e3d663b2-9aef-4d55-c8aa-0f4f2b448ec8"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection for Mix using the normalized dataset\n",
    "ds_Mix_normFS50 = FeatureSelection(ds_Mix_norm,\"Mix\",nFeats=210) # select the best 210 features (210/420)\n",
    "ds_Mix_normFS50 # check the feature selected dataset for Mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BBd567XgrWn"
   },
   "source": [
    "### 25% of descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "ycKIsYXZJY5A",
    "outputId": "fb567adf-cc90-4fe8-e573-c27ee53ff34e"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection for AAC using the normalized dataset\n",
    "ds_AAC_normFS25 = FeatureSelection(ds_AAC_norm,\"AAC\",nFeats=5) # select the best 5 features (5/20)\n",
    "ds_AAC_normFS25 # check the feature selected dataset for AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "I97ReeKyM0LN",
    "outputId": "e9cefa7c-75b5-4ca9-c752-e01385cdec73"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection for DPC using the normalized dataset\n",
    "ds_DPC_normFS25 = FeatureSelection(ds_DPC_norm,\"DPC\",nFeats=100) # select the best 100 features (100/400)\n",
    "ds_DPC_normFS25 # check the feature selected dataset for DPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "GJP9scM2OLm2",
    "outputId": "07446a40-4a9c-459d-ad67-cdc34585032b"
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection for Mix using the normalized dataset\n",
    "ds_Mix_normFS25 = FeatureSelection(ds_Mix_norm,\"Mix\",nFeats=105) # select the best 105 features (105/420)\n",
    "ds_Mix_normFS25 # check the feature selected dataset for Mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mEgJugyOizV"
   },
   "source": [
    "### ML classifiers for metastasic vs non-metastasic protein sequences\n",
    "\n",
    "We have 9 datasets to use with different ML classifier:\n",
    "*   3 normalized datasets with all descriptors: ds_AAC_norm, ds_DPC_norm, ds_Mix_norm\n",
    "*  3 dataset with 50% of the best features selected from the previous datasets: ds_AAC_normFS50 (only 10 features from 20), ds_DPC_normFS50 (only 200 features from 400), ds_Mix_normFS50 (only 210 features from 420).\n",
    "*   3 dataset with 25% of the best features selected from the previous datasets: ds_AAC_normFS25 (only 5 features from 20), ds_DPC_normFS25 (only 100 features from 400), ds_Mix_normFS25 (only 105 features from 420).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulyyU534MzMB"
   },
   "source": [
    "### Functions for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1xiKqCeco2X"
   },
   "outputs": [],
   "source": [
    "nfold = 10 # number of fold-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cw5Kqe9nWHEl"
   },
   "outputs": [],
   "source": [
    "# Create a function that will build ML models for one dataset\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, cohen_kappa_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def MLOuterCV(Xdata, Ydata, folds, seed=2024):\n",
    "    # define classifiers labels in results\n",
    "    names = ['NB', 'KNN', 'LDA', 'SVM', 'SVMrbf', 'LR', 'MLP', 'DT', 'RF', 'XGB']\n",
    "\n",
    "    classifiers = [GaussianNB(),\n",
    "                   KNeighborsClassifier(5),\n",
    "                   LinearDiscriminantAnalysis(solver='svd'),  # no random_state\n",
    "                   SVC(kernel=\"linear\", random_state=seed, gamma='scale'),\n",
    "                   SVC(kernel='rbf', random_state=seed, gamma='scale'),\n",
    "                   LogisticRegression(solver='lbfgs', random_state=seed),\n",
    "                   MLPClassifier(random_state=seed, max_iter=50000, shuffle=False),\n",
    "                   DecisionTreeClassifier(random_state=seed),\n",
    "                   RandomForestClassifier(n_jobs=-1, random_state=seed),\n",
    "                   XGBClassifier(n_jobs=-1, seed=seed)\n",
    "                   ]\n",
    "\n",
    "    # results dataframe: each column for a classifier\n",
    "    df_res_auroc = pd.DataFrame(columns=names, dtype=object)\n",
    "    df_res_f1 = pd.DataFrame(columns=names, dtype=object)\n",
    "    df_res_kappa = pd.DataFrame(columns=names, dtype=object)\n",
    "    df_res_recall = pd.DataFrame(columns=names, dtype=object)\n",
    "    df_res_precision = pd.DataFrame(columns=names, dtype=object)\n",
    "\n",
    "    # build each classifier\n",
    "    print('* Building ' + str(folds) + '-fold CV for ' + str(len(names)) + ' classifiers:', str(names))\n",
    "    total = time.time()\n",
    "\n",
    "    # define a fold-CV for all the classifier\n",
    "    outer_cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    print('ML method, AUROC Mean, AUROC SD, F1 Mean, F1 SD, Kappa Mean, Kappa SD, Recall Mean, Recall SD, Precision Mean, Precision SD, Time (min)')\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        start = time.time()\n",
    "\n",
    "        # evaluate pipeline\n",
    "        scores_auroc = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='roc_auc', n_jobs=-1)\n",
    "        scores_f1 = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='f1', n_jobs=-1)\n",
    "        scores_kappa = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
    "        scores_recall = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='recall', n_jobs=-1)\n",
    "        scores_precision = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='precision', n_jobs=-1)\n",
    "\n",
    "        df_res_auroc[name] = scores_auroc\n",
    "        df_res_f1[name] = scores_f1\n",
    "        df_res_kappa[name] = scores_kappa\n",
    "        df_res_recall[name] = scores_recall\n",
    "        df_res_precision[name] = scores_precision\n",
    "\n",
    "        results_string = ('%s, %0.3f, %0.4f, %0.3f, %0.4f, %0.3f, %0.4f, %0.3f, %0.4f, %0.3f, %0.4f, %0.1f' %\n",
    "                        (name, scores_auroc.mean(), scores_auroc.std(),\n",
    "                          scores_f1.mean(), scores_f1.std(),\n",
    "                          scores_kappa.mean(), scores_kappa.std(),\n",
    "                          scores_recall.mean(), scores_recall.std(),\n",
    "                          scores_precision.mean(), scores_precision.std(),\n",
    "                          (time.time() - start) / 60))\n",
    "        print(results_string)\n",
    "\n",
    "    print('Total time:', (time.time() - total) / 60, ' mins')\n",
    "    return [df_res_auroc, df_res_f1, df_res_kappa, df_res_recall, df_res_precision]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSvD-dz0FQDu"
   },
   "outputs": [],
   "source": [
    "# Function to build ML models, write the results plot box plots for a dataframe\n",
    "\n",
    "def MLmodels(df, df_fold, nfold, label=\"X\", label_y=\"Y\"):\n",
    "    df_results = None\n",
    "    df_fold['Dataset'] = label\n",
    "    df_fold['folds'] = nfold\n",
    "\n",
    "    # add each result to a summary dataframe\n",
    "    df_results = pd.concat([df_results,df_fold])\n",
    "    summaryFile = resPath+'ML_'+label+'_'+label_y+'.csv' # ML metrics results\n",
    "    boxplotFile = resPath+'ML_'+label+'_'+label_y+'.png' # box plot of the metrics\n",
    "\n",
    "    # save all results\n",
    "    print('\\n==>> Saving summary', summaryFile)\n",
    "    df_results.to_csv(summaryFile, index=False)\n",
    "\n",
    "    # save boxplot\n",
    "    classifierNames = list(df_results.columns)\n",
    "    classifierNames.remove('Dataset')\n",
    "    classifierNames.remove('folds')\n",
    "\n",
    "    foldTypes=[nfold]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    print('==> Fold =', nfold)\n",
    "    grouped = df_results[df_results['folds']==nfold].drop(['folds'], axis=1).groupby('Dataset')\n",
    "    #grouped.boxplot(figsize=(16,12), return_type='axes')\n",
    "    grouped.boxplot(return_type='axes')\n",
    "    plt.title(\"\")\n",
    "    #plt.xlabel(\"Machine Learning methods for \"+label,size=18)\n",
    "    #plt.ylabel(\"AUROC (\"+str(nfold)+\"-fold CV)\",size=18)\n",
    "    plt.xlabel(\"Machine Learning methods for \"+ label)\n",
    "    plt.ylabel(label_y + \"(\"+str(nfold)+\"-fold CV)\")\n",
    "    #plt.tick_params(labelsize=14)\n",
    "    plt.ylim(0,1.0)\n",
    "    #plt.savefig(boxplotFile, dpi=1200)\n",
    "    plt.savefig(boxplotFile)\n",
    "    plt.show()\n",
    "\n",
    "    df_results\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZinYbt4hErQ"
   },
   "source": [
    "### ML models and box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P-PtNX70Ww91",
    "outputId": "4ac8ae4c-b374-4a97-f3dd-fe5f29a3c2e7"
   },
   "outputs": [],
   "source": [
    "# ML for AAC normalized dataset with all descriptors (no feature selection)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_norm)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_AAC, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_AAC_norm, df_res_auroc, nfold, label=\"AAC_norm\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_AAC_norm, df_res_f1, nfold, label=\"AAC_norm\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_AAC_norm, df_res_kappa_AAC, nfold, label=\"AAC_norm\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_AAC_norm, df_res_recall, nfold, label=\"AAC_norm\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_AAC_norm, df_res_precision, nfold, label=\"AAC_norm\", label_y=\"Precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EBKFFxdUOW-m",
    "outputId": "b0df068e-90be-4798-e176-395ba2b4b11e"
   },
   "outputs": [],
   "source": [
    "# ML for DPC normalized dataset with all descriptors (no feature selection)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_norm)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_DPC, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_DPC_norm, df_res_auroc, nfold, label=\"DPC_norm\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_DPC_norm, df_res_f1, nfold, label=\"DPC_norm\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_DPC_norm, df_res_kappa_DPC, nfold, label=\"DPC_norm\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_DPC_norm, df_res_recall, nfold, label=\"DPC_norm\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_DPC_norm, df_res_precision, nfold, label=\"DPC_norm\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_kj_6O90gBt-",
    "outputId": "360eead3-4b87-4607-a2a5-98ba17e99fac"
   },
   "outputs": [],
   "source": [
    "# ML for Mix normalized dataset with all descriptors (no feature selection)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_norm)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_Mix, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_Mix_norm, df_res_auroc, nfold, label=\"Mix_norm\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_Mix_norm, df_res_f1, nfold, label=\"Mix_norm\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_Mix_norm, df_res_kappa_Mix, nfold, label=\"Mix_norm\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_Mix_norm, df_res_recall, nfold, label=\"Mix_norm\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_Mix_norm, df_res_precision, nfold, label=\"Mix_norm\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF2M9zLoQ1Jk"
   },
   "source": [
    "### 50% of descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HBeWCEGsgIyY",
    "outputId": "81efcf68-245e-4090-a5c1-fa09a0f2372f"
   },
   "outputs": [],
   "source": [
    "# ML for AAC normalized dataset with selected features\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS50)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS50, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_AAC_normFS50, df_res_auroc, nfold, label=\"AAC_normFS50\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_AAC_normFS50, df_res_f1, nfold, label=\"AAC_normFS50\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_AAC_normFS50, df_res_kappa_AAC_FS50, nfold, label=\"AAC_normFS50\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_AAC_normFS50, df_res_recall, nfold, label=\"AAC_normFS50\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_AAC_normFS50, df_res_precision, nfold, label=\"AAC_normFS50\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JxFGBnIOgQFC",
    "outputId": "56988a31-2844-49f0-8f12-4571c959c65e"
   },
   "outputs": [],
   "source": [
    "# ML for DPC normalized dataset with selected features\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS50)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS50, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_DPC_normFS50, df_res_auroc, nfold, label=\"DPC_normFS50\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_DPC_normFS50, df_res_f1, nfold, label=\"DPC_normFS50\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_DPC_normFS50, df_res_kappa_DPC_FS50, nfold, label=\"DPC_normFS50\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_DPC_normFS50, df_res_recall, nfold, label=\"DPC_normFS50\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_DPC_normFS50, df_res_precision, nfold, label=\"DPC_normFS50\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ipW-LnqIgUDZ",
    "outputId": "178662c8-0b3d-4c5d-8397-be1e2236b827"
   },
   "outputs": [],
   "source": [
    "# ML for Mix normalized dataset with selected features\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS50)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS50, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_Mix_normFS50, df_res_auroc, nfold, label=\"Mix_normFS50\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_Mix_normFS50, df_res_f1, nfold, label=\"Mix_normFS50\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_Mix_normFS50, df_res_kappa_Mix_FS50, nfold, label=\"Mix_normFS50\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_Mix_normFS50, df_res_recall, nfold, label=\"Mix_normFS50\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_Mix_normFS50, df_res_precision, nfold, label=\"Mix_normFS50\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqVLwnnLRGXJ"
   },
   "source": [
    "### 25% of descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MXWCPz6Vga_2",
    "outputId": "4e7254e7-5bb9-42d5-8966-6cca4929bfca"
   },
   "outputs": [],
   "source": [
    "# ML for AAC normalized dataset with selected features\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS25)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS25, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_AAC_normFS25, df_res_auroc, nfold, label=\"AAC_normFS25\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_AAC_normFS25, df_res_f1, nfold, label=\"AAC_normFS25\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_AAC_normFS25, df_res_kappa_AAC_FS25, nfold, label=\"AAC_normFS25\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_AAC_normFS25, df_res_recall, nfold, label=\"AAC_normFS25\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_AAC_normFS25, df_res_precision, nfold, label=\"AAC_normFS25\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8tlTkf-WRYqI",
    "outputId": "69232597-b482-4df5-9c88-77354e259f5c"
   },
   "outputs": [],
   "source": [
    "# ML for DPC normalized dataset with selected features\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS25)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS25, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_DPC_normFS25, df_res_auroc, nfold, label=\"DPC_normFS25\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_DPC_normFS25, df_res_f1, nfold, label=\"DPC_normFS25\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_DPC_normFS25, df_res_kappa_DPC_FS25, nfold, label=\"DPC_normFS25\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_DPC_normFS25, df_res_recall, nfold, label=\"DPC_normFS25\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_DPC_normFS25, df_res_precision, nfold, label=\"DPC_normFS25\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fgxiDnyqRfE_",
    "outputId": "b8880bc3-6ff9-4945-e0cb-debef60c17a0"
   },
   "outputs": [],
   "source": [
    "# ML for Mix normalized dataset with selected features\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS25)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS25, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_Mix_normFS25, df_res_auroc, nfold, label=\"Mix_normFS25\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_Mix_normFS25, df_res_f1, nfold, label=\"Mix_normFS25\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_Mix_normFS25, df_res_kappa_Mix_FS25, nfold, label=\"Mix_normFS25\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_Mix_normFS25, df_res_recall, nfold, label=\"Mix_normFS25\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_Mix_normFS25, df_res_precision, nfold, label=\"Mix_normFS25\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38pAQmiFAKFZ"
   },
   "source": [
    "### Statistical Analysis\n",
    "\n",
    "### For each dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCsSLk_kK358"
   },
   "source": [
    "#### Normality: Shapiro-Wilk and QQ Plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYU32uZxfOAr"
   },
   "source": [
    "#### Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "YiBNeW01WG_v",
    "outputId": "365cac01-0ed3-422b-d46d-1c493a65caaa"
   },
   "outputs": [],
   "source": [
    "# Remove the last two columns from each dataframe\n",
    "\n",
    "dicc = {\n",
    "    \"df_res_kappa_AAC\": df_res_kappa_AAC,\n",
    "    \"df_res_kappa_DPC\": df_res_kappa_DPC,\n",
    "    \"df_res_kappa_Mix\": df_res_kappa_Mix,\n",
    "    \"df_res_kappa_AAC_FS50\": df_res_kappa_AAC_FS50,\n",
    "    \"df_res_kappa_DPC_FS50\": df_res_kappa_DPC_FS50,\n",
    "    \"df_res_kappa_Mix_FS50\": df_res_kappa_Mix_FS50,\n",
    "    \"df_res_kappa_AAC_FS25\": df_res_kappa_AAC_FS25,\n",
    "    \"df_res_kappa_DPC_FS25\": df_res_kappa_DPC_FS25,\n",
    "    \"df_res_kappa_Mix_FS25\": df_res_kappa_Mix_FS25\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "def remove(df):\n",
    "    return df.iloc[:, :-2]\n",
    "\n",
    "for dataset_name, dataset in dicc.items():\n",
    "    datasets[dataset_name] = remove(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bw9er441k9K6"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "def shapiro_test(df_res_kappa, dataset_name):\n",
    "  ''' H0: The null hypothesis states that the data come from a population with a normal distribution.\n",
    "      H1: The alternative hypothesis suggests that the data do not come from a population with a normal distribution.'''\n",
    "\n",
    "  # Shapiro-Wilk\n",
    "  statistic, p_value = shapiro(df_res_kappa)\n",
    "\n",
    "  # Results\n",
    "  if p_value < 0.05:\n",
    "    print(\"Shapiro-Wilk test rejects the null hypothesis.\")\n",
    "    print(\"The dataset \"f\"\\033[1m{dataset_name}\\033[0m DOES NOT FOLLOWS a normal distribution.\")\n",
    "\n",
    "  else:\n",
    "    print(\"Shapiro-Wilk test does not reject the null hypothesis.\")\n",
    "    print(\"The dataset \"f\"\\033[1m{dataset_name}\\033[0m FOLLOWS a normal distribution.\")\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRIj1hoa5tou"
   },
   "outputs": [],
   "source": [
    "# Call Shapiro-Wilks function for each data set\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    shapiro_test(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWtNB_z_LH_A"
   },
   "source": [
    "#### QQ Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsEGf7AQLMaG"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def assess_normality(df, dataset_name):\n",
    "\n",
    "  # Calculate row averages and convert to a single column DataFrame\n",
    "  y = df.values.flatten()\n",
    "\n",
    "  # Create a sequence of integers as indexes for the columns\n",
    "  x = range (len(y))\n",
    "\n",
    "  # Fit a linear regression model and obtain the residuals\n",
    "  model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "  residuals = model.resid\n",
    "\n",
    "  # Plot QQ plot\n",
    "  sm.qqplot(residuals, line='s')\n",
    "  plt.title(f'Normality Assessment of Residuals for {dataset_name}', fontsize=18)\n",
    "  plt.xlabel('Theoretical Quantiles', fontsize=15)\n",
    "  plt.ylabel('Sample Residual Quantiles', fontsize=15)\n",
    "  plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG__Sk9oRH2Z"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in datasets.items():\n",
    "    assess_normality(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW-xl-vYAFs5"
   },
   "source": [
    "#### ANOVA\n",
    "For those datasets following a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDERLK1DAu8c"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "def anova(df_res_kappa, dataset_name):\n",
    "\n",
    "  '''H0: The means of the classifiers are equal.\n",
    "     H1: The means of the classifiers are not equal.'''\n",
    "\n",
    "  # ANOVA\n",
    "  f_statistic, p_value = f_oneway(*[df_res_kappa[column] for column in df_res_kappa.columns])\n",
    "\n",
    "  # Results\n",
    "  print(\"Statistical F:\", f_statistic)\n",
    "  print(\"P value:\", p_value)\n",
    "\n",
    "  if p_value < 0.05:\n",
    "    print(\"Rejects the null hypothesis.\")\n",
    "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE statistically significant differences between the classifiers's means.\")\n",
    "\n",
    "  else:\n",
    "    print(\"Does not reject the null hypothesis.\")\n",
    "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE NO statistically significant differences between the classifiers's means.\")\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgLmNVyUE6o4"
   },
   "outputs": [],
   "source": [
    "norm_dicc = {\n",
    "    \"df_res_kappa_AAC\": df_res_kappa_AAC,\n",
    "    \"df_res_kappa_DPC\": df_res_kappa_DPC,\n",
    "    \"df_res_kappa_AAC_FS50\": df_res_kappa_AAC_FS50,\n",
    "    \"df_res_kappa_DPC_FS50\": df_res_kappa_DPC_FS50,\n",
    "    \"df_res_kappa_Mix_FS50\": df_res_kappa_Mix_FS50,\n",
    "    \"df_res_kappa_AAC_FS25\": df_res_kappa_AAC_FS25,\n",
    "}\n",
    "\n",
    "norm_datasets = {}\n",
    "for dataset_name, dataset in norm_dicc.items():\n",
    "    norm_datasets[dataset_name] = remove(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztguixlzEqsz"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in norm_datasets.items():\n",
    "    anova(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxWzJG6G_dDu"
   },
   "source": [
    "#### Kruskal-Wallis\n",
    "For those datasets that do not follow a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9P_g7NbYGWt9"
   },
   "outputs": [],
   "source": [
    "not_norm_dicc = {\n",
    "    \"df_res_kappa_Mix\": df_res_kappa_Mix,\n",
    "    \"df_res_kappa_DPC_FS25\": df_res_kappa_DPC_FS25,\n",
    "    \"df_res_kappa_Mix_FS25\": df_res_kappa_Mix_FS25\n",
    "}\n",
    "\n",
    "not_norm_datasets = {}\n",
    "for dataset_name, dataset in not_norm_dicc.items():\n",
    "    not_norm_datasets[dataset_name] = remove(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqN_PpdtfTRQ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "def kruskal_w(df_res_kappa, dataset_name):\n",
    "\n",
    "  '''H0: The performance distributions of the classifiers are equal.\n",
    "     H1: At least one classifier's performance distribution is different from the others.'''\n",
    "\n",
    "  # Kruskal-Wallis\n",
    "  h_statistic, p_value = kruskal(*[df_res_kappa[column] for column in df_res_kappa.columns])\n",
    "\n",
    "  # Results\n",
    "  print(\"Statistical F:\", h_statistic)\n",
    "  print(\"P value:\", p_value)\n",
    "\n",
    "  if p_value < 0.05:\n",
    "    print(\"Rejects the null hypothesis.\")\n",
    "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE IS at least one classifier whose performance is statistically different from the rest.\")\n",
    "\n",
    "  else:\n",
    "    print(\"Does not reject the null hypothesis.\")\n",
    "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE NO statistically significant differences in the performance of the classifiers.\")\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qha043kfJ2GZ"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in not_norm_datasets.items():\n",
    "    kruskal_w(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAI4pE8ZbmiV"
   },
   "source": [
    "#### Levene's test\n",
    "Variance of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxHqM6nZcBOw"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def levene_test(dataset, dataset_name):\n",
    "\n",
    "  ''' H0: The variances of the classifiers are homogeneous.\n",
    "      H1: At least one of the variances of the classifiers differs from the others.'''\n",
    "\n",
    "  # Levene's test\n",
    "  statistic, p_value = levene(*[dataset[column] for column in dataset.columns])\n",
    "\n",
    "  # Results\n",
    "  print(\"Levene's Test Statistic:\", statistic)\n",
    "  print(\"p-value:\", p_value)\n",
    "\n",
    "  # p-value\n",
    "  if p_value < 0.05:\n",
    "      print(\"Reject the null hypothesis of equal variances.\")\n",
    "      print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE IS at least one classifier whose variance is statistically different from the others.\")\n",
    "\n",
    "  else:\n",
    "      print(\"Does no reject null hypothesis of equal variances.\")\n",
    "      print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE NO statistically significant differences between the variance of the classifiers.\")\n",
    "\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDAtK3aWeg7k"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in datasets.items():\n",
    "    levene_test(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVmGROwoSvJ4"
   },
   "source": [
    "#### Tukey's Test\n",
    "Assumes that the data are approximately normally distributed and that the variances of the groups are homogeneous.\n",
    "\n",
    "Determine whether there are significant differences between the means of classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSxuZxHEtgAO"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "def tukey_test(dataset, dataset_name):\n",
    "    # List of classifiers\n",
    "    classifiers = dataset.columns.tolist()\n",
    "\n",
    "    # List to store data for each classifier\n",
    "    data = [dataset[classifier].values for classifier in classifiers]\n",
    "\n",
    "    # Flatten the list of lists into a single list\n",
    "    flattened_data = np.concatenate(data)\n",
    "\n",
    "    # Create groups for each classifier\n",
    "    groups = [classifier for classifier in classifiers for _ in range(len(dataset))]\n",
    "\n",
    "    # Tukey's test\n",
    "    tukey_result = pairwise_tukeyhsd(flattened_data, groups)\n",
    "\n",
    "    # Results\n",
    "    print(\"\\033[1mResults for the dataset \"f\"{dataset_name}\\033[0m\")\n",
    "    print()\n",
    "    print(tukey_result)\n",
    "    print()\n",
    "\n",
    "    # Plot the results of Tukey's test\n",
    "    tukey_result.plot_simultaneous()\n",
    "    plt.title(f\"Tukey Test for {dataset_name}. Comparisons Among Classifiers\")\n",
    "    plt.xlabel(\"Metric Value\")\n",
    "    plt.ylabel(\"Classifiers\")\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrEujoI-CUOt"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in datasets.items():\n",
    "    tukey_test(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plecwDZvZfc7"
   },
   "source": [
    "### Statistical Analysis\n",
    "\n",
    "### For all datasets:\n",
    "\n",
    "### NB classifier\n",
    "For the comparison of all datasets, the NB classifier of each dataset is selected as there are no significant differences between classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQelCEK3c2a1"
   },
   "outputs": [],
   "source": [
    "def NB_columns(dataframes, dataframe_names):\n",
    "    NB_columns = []\n",
    "\n",
    "    for df, df_name in zip(dataframes, dataframe_names):\n",
    "        # Extract the NB column from each dataframe\n",
    "        NB_column = pd.DataFrame(df['NB'].values)\n",
    "\n",
    "        # Rename the column\n",
    "        new_name = df_name + '_NB'\n",
    "        NB_column = NB_column.rename(columns={0: new_name})\n",
    "\n",
    "        NB_columns.append(NB_column)\n",
    "\n",
    "    # Combine all columns into a single dataframe\n",
    "    combined_df = pd.concat(NB_columns, axis=1)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN7629CsdNHh",
    "outputId": "f2a33324-b0ac-4951-c21f-a1d34fc8333c"
   },
   "outputs": [],
   "source": [
    "# Function call\n",
    "\n",
    "kappa_all_datasets = [df_res_kappa_AAC, df_res_kappa_DPC, df_res_kappa_Mix, df_res_kappa_AAC_FS50, df_res_kappa_DPC_FS50, df_res_kappa_Mix_FS50, df_res_kappa_AAC_FS25, df_res_kappa_DPC_FS25, df_res_kappa_Mix_FS25]\n",
    "dataframe_names = ['df_res_kappa_AAC', 'df_res_kappa_DPC', 'df_res_kappa_Mix', 'df_res_kappa_AAC_FS50', 'df_res_kappa_DPC_FS50', 'df_res_kappa_Mix_FS50', 'df_res_kappa_AAC_FS25', 'df_res_kappa_DPC_FS25', 'df_res_kappa_Mix_FS25']\n",
    "\n",
    "final_df = NB_columns(kappa_all_datasets, dataframe_names)\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHp-sd7RZ3Ss"
   },
   "source": [
    "#### Normality: Shapiro-Wilk and QQ Plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4bd_b6PZ4tv"
   },
   "source": [
    "#### Shapiro-Wilk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NICOhSsDZfLj",
    "outputId": "65478903-bf62-4aa8-ec1a-0bab129a0811"
   },
   "outputs": [],
   "source": [
    "# One-dimensional array\n",
    "kappa_data = final_df.values.flatten()\n",
    "\n",
    "# Shapiro-Wilk\n",
    "statistic, p_value = shapiro(kappa_data)\n",
    "\n",
    "# Results\n",
    "print(\"Statistical:\", statistic)\n",
    "print(\"P value:\", p_value)\n",
    "print()\n",
    "\n",
    "if p_value < 0.05:\n",
    "  print(\"Shapiro-Wilk test rejects the null hypothesis.\")\n",
    "  print(\"The NB Dataset DOES NOT FOLLOWS a normal distribution.\")\n",
    "\n",
    "else:\n",
    "  print(\"Shapiro-Wilk test does not reject the null hypothesis.\")\n",
    "  print(\"The NB Dataset FOLLOWS a normal distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5vIjAgKfWNZ"
   },
   "source": [
    "#### QQ-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "QGNBrLUMZ4Py",
    "outputId": "82055490-f35a-471b-b0aa-454aa90d52b5"
   },
   "outputs": [],
   "source": [
    "# Call asses_normality function\n",
    "\n",
    "assess_normality(final_df, 'NB Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtYcI9l4iTPN"
   },
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lW8_hwajA3v3",
    "outputId": "bce18f43-49aa-4e4a-bfa3-3775b9f48820"
   },
   "outputs": [],
   "source": [
    "# Call anova function\n",
    "\n",
    "anova(final_df, 'NB Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyh0lEsri7sz"
   },
   "source": [
    "#### Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sqFzREbBZ6u",
    "outputId": "2a6c1e0a-8e1f-408d-c142-695e7c4a6132"
   },
   "outputs": [],
   "source": [
    "# Call levene_test function\n",
    "\n",
    "levene_test(final_df, 'NB Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcOP5azMj_9Z"
   },
   "source": [
    "#### Tukey's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zmXry5q0j_pC",
    "outputId": "d25e980e-3ab3-470a-a577-785b5e80ce19"
   },
   "outputs": [],
   "source": [
    "# Call tukey_test function\n",
    "tukey_test(final_df, 'DB Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCl-jj-vfOZd"
   },
   "source": [
    "## Multivariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1WfzqAVLOS3"
   },
   "outputs": [],
   "source": [
    "# Multivariate feature selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Feature selection function using RFE with Random Forest\n",
    "def FeatureSelectionWithRFE(df, label, nFeats=1):\n",
    "    if nFeats == 0:\n",
    "        print(\"\\n NO feature selection\")\n",
    "        return df\n",
    "\n",
    "    # Separating features and target variable using getDataFromDataFrame\n",
    "    Xdata, Ydata, Features = getDataFromDataFrame(df)\n",
    "\n",
    "    # Feature selection using RFE\n",
    "    print('\\n-> Multivariate Feature selection with RFE and Random Forest')\n",
    "    print('Initial columns:', list(df.columns))\n",
    "\n",
    "    # Define the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Configure RFE\n",
    "    selector = RFE(estimator=rf_model, n_features_to_select=nFeats, step=1)\n",
    "\n",
    "    # Adjust the selector to the data\n",
    "    selector = selector.fit(Xdata, Ydata)\n",
    "\n",
    "    # Obtain the selected characteristics\n",
    "    SelFeatures = []\n",
    "    for i in selector.get_support(indices=True):\n",
    "        SelFeatures.append(Features[i])\n",
    "\n",
    "    # Create the new DataFrame with the selected features\n",
    "    Xdata_selected = selector.transform(Xdata)\n",
    "    df_selected = pd.DataFrame(Xdata_selected, columns=SelFeatures)\n",
    "    df_selected['Class'] = Ydata\n",
    "\n",
    "    print('Final columns:', list(df_selected.columns))\n",
    "\n",
    "    # Save the dataset with the selected characteristics\n",
    "    selectFile = dsPath + 'ds' + label + '.normFS_RFE(' + str(nFeats) + ').csv'\n",
    "    print('* Save selected features dataset:', selectFile)\n",
    "    df_selected.to_csv(selectFile, index=False)\n",
    "\n",
    "    print('Done!')\n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y1dmtimdSY6I",
    "outputId": "e0f6a120-6623-4d9a-923e-2b5ce8f4ce26"
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "\n",
    "ds_AAC_norm_RFE = FeatureSelectionWithRFE(ds_AAC_norm, \"AAC\", nFeats=20)  # ALL\n",
    "ds_DPC_norm_RFE = FeatureSelectionWithRFE(ds_DPC_norm, \"DPC\", nFeats=400)  # ALL\n",
    "ds_Mix_norm_RFE = FeatureSelectionWithRFE(ds_Mix_norm, \"Mix\", nFeats=420)  # ALL\n",
    "ds_AAC_norm_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2C1yAEUQ4X2",
    "outputId": "91149686-5c4d-427b-f10c-79aca99fd363"
   },
   "outputs": [],
   "source": [
    "ds_AAC_normFS50_RFE = FeatureSelectionWithRFE(ds_AAC_norm, \"AAC\", nFeats=10)  # 50%\n",
    "ds_DPC_normFS50_RFE = FeatureSelectionWithRFE(ds_DPC_norm, \"DPC\", nFeats=200)  # 50%\n",
    "ds_Mix_normFS50_RFE = FeatureSelectionWithRFE(ds_Mix_norm, \"Mix\", nFeats=210)  # 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnGyDyMIQ6A4",
    "outputId": "b190ba0b-7f85-4d5d-a973-5969740da451"
   },
   "outputs": [],
   "source": [
    "ds_AAC_normFS25_RFE = FeatureSelectionWithRFE(ds_AAC_norm, \"AAC\", nFeats=5)  # 25%\n",
    "ds_DPC_normFS25_RFE = FeatureSelectionWithRFE(ds_DPC_norm, \"DPC\", nFeats=100)  # 25%\n",
    "ds_Mix_normFS25_RFE = FeatureSelectionWithRFE(ds_Mix_norm, \"Mix\", nFeats=105)  # 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NzbKki8QTFA3",
    "outputId": "ea0823bc-37cc-46a2-d2e8-8a51691f44f9"
   },
   "outputs": [],
   "source": [
    "# ML for AAC normalized dataset with all descriptors (no feature selection)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_norm_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_AAC_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_AAC_norm_RFE, df_res_auroc, nfold, label=\"AAC_norm_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_AAC_norm_RFE, df_res_f1, nfold, label=\"AAC_norm_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_AAC_norm_RFE, df_res_kappa_AAC_RFE, nfold, label=\"AAC_norm_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_AAC_norm_RFE, df_res_recall, nfold, label=\"AAC_norm_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_AAC_norm_RFE, df_res_precision, nfold, label=\"AAC_norm_RFE\", label_y=\"Precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_2nA5a6OTgKR",
    "outputId": "4a8ae4a9-2ee3-47b6-ea1f-618897f6be8a"
   },
   "outputs": [],
   "source": [
    "# ML for DPC normalized dataset with all descriptors (no feature selection)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_norm_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_DPC_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_DPC_norm_RFE, df_res_auroc, nfold, label=\"DPC_norm_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_DPC_norm_RFE, df_res_f1, nfold, label=\"DPC_norm_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_DPC_norm_RFE, df_res_kappa_DPC_RFE, nfold, label=\"DPC_norm_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_DPC_norm_RFE, df_res_recall, nfold, label=\"DPC_norm_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_DPC_norm_RFE, df_res_precision, nfold, label=\"DPC_norm_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DIvMofBEUgiZ",
    "outputId": "30652f8d-1b17-44ae-c876-74697189b536"
   },
   "outputs": [],
   "source": [
    "# ML for Mix normalized dataset with all descriptors (no feature selection)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_norm_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_Mix_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_Mix_norm_RFE, df_res_auroc, nfold, label=\"Mix_norm_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_Mix_norm_RFE, df_res_f1, nfold, label=\"Mix_norm_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_Mix_norm_RFE, df_res_kappa_Mix_RFE, nfold, label=\"Mix_norm_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_Mix_norm_RFE, df_res_recall, nfold, label=\"Mix_norm_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_Mix_norm_RFE, df_res_precision, nfold, label=\"Mix_norm_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uoMZO9X3UxAn",
    "outputId": "3e8a956e-2fb8-4755-ac06-0be15550183f"
   },
   "outputs": [],
   "source": [
    "# ML for AAC normalized dataset with selected features (50%)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS50_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS50_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_AAC_normFS50_RFE, df_res_auroc, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_AAC_normFS50_RFE, df_res_f1, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_AAC_normFS50_RFE, df_res_kappa_AAC_FS50_RFE, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_AAC_normFS50_RFE, df_res_recall, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_AAC_normFS50_RFE, df_res_precision, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ox3QC5NVTgZP",
    "outputId": "96e75e76-8b83-40c4-fd30-ddecdbff2756"
   },
   "outputs": [],
   "source": [
    "# ML for DPC normalized dataset with selected features (50%)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS50_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS50_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_DPC_normFS50_RFE, df_res_auroc, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_DPC_normFS50_RFE, df_res_f1, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_DPC_normFS50_RFE, df_res_kappa_DPC_FS50_RFE, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_DPC_normFS50_RFE, df_res_recall, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_DPC_normFS50_RFE, df_res_precision, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "R0-wmWdPVwRc",
    "outputId": "3dd9cc0d-fd82-48d3-ab8f-d23e89529fef"
   },
   "outputs": [],
   "source": [
    "# ML for Mix normalized dataset with selected features (50%)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS50_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS50_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_Mix_normFS50_RFE, df_res_auroc, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_Mix_normFS50_RFE, df_res_f1, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_Mix_normFS50_RFE, df_res_kappa_Mix_FS50_RFE, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_Mix_normFS50_RFE, df_res_recall, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_Mix_normFS50_RFE, df_res_precision, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A_i5RfwaV9xy",
    "outputId": "a709aa04-6bba-4f79-9519-ea65288f5c14"
   },
   "outputs": [],
   "source": [
    "# ML for AAC normalized dataset with selected features (25%)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS25_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS25_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_AAC_normFS25_RFE, df_res_auroc, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_AAC_normFS25_RFE, df_res_f1, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_AAC_normFS25_RFE, df_res_kappa_AAC_FS25_RFE, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_AAC_normFS25_RFE, df_res_recall, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_AAC_normFS25_RFE, df_res_precision, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v7HCUyrFWMBk",
    "outputId": "a8b8074d-973f-4743-aa7f-a423fa8bd87a"
   },
   "outputs": [],
   "source": [
    "# ML for DPC normalized dataset with selected features (25%)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS25_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS25_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_DPC_normFS25_RFE, df_res_auroc, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_DPC_normFS25_RFE, df_res_f1, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_DPC_normFS25_RFE, df_res_kappa_DPC_FS25_RFE, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_DPC_normFS25_RFE, df_res_recall, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_DPC_normFS25_RFE, df_res_precision, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MDMHoBHbWXSB",
    "outputId": "1978f9dc-eeff-48d2-848d-13b3cfe41bb2"
   },
   "outputs": [],
   "source": [
    "# ML for Mix normalized dataset with selected features (25%)\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS25_RFE)\n",
    "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS25_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
    "\n",
    "# AUROC\n",
    "MLmodels(ds_Mix_normFS25_RFE, df_res_auroc, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"AUROC\")\n",
    "\n",
    "# F1_Score\n",
    "MLmodels(ds_Mix_normFS25_RFE, df_res_f1, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"F1_Score\")\n",
    "\n",
    "# Kappa_Score\n",
    "MLmodels(ds_Mix_normFS25_RFE, df_res_kappa_Mix_FS25_RFE, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"Kappa_Score\")\n",
    "\n",
    "# Recall\n",
    "MLmodels(ds_Mix_normFS25_RFE, df_res_recall, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"Recall\")\n",
    "\n",
    "# Precision\n",
    "MLmodels(ds_Mix_normFS25_RFE, df_res_precision, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BizatuYFRxiy"
   },
   "source": [
    "### Statistical Analysis\n",
    "### For each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4IL6B8RXUhK"
   },
   "outputs": [],
   "source": [
    "# Remove the last two columns from each dataframe\n",
    "\n",
    "dicc_RFE = {\n",
    "    \"df_res_kappa_AAC_RFE\": df_res_kappa_AAC_RFE,\n",
    "    \"df_res_kappa_DPC_RFE\": df_res_kappa_DPC_RFE,\n",
    "    \"df_res_kappa_Mix_RFE\": df_res_kappa_Mix_RFE,\n",
    "    \"df_res_kappa_AAC_FS50_RFE\": df_res_kappa_AAC_FS50_RFE,\n",
    "    \"df_res_kappa_DPC_FS50_RFE\": df_res_kappa_DPC_FS50_RFE,\n",
    "    \"df_res_kappa_Mix_FS50_RFE\": df_res_kappa_Mix_FS50_RFE,\n",
    "    \"df_res_kappa_AAC_FS25_RFE\": df_res_kappa_AAC_FS25_RFE,\n",
    "    \"df_res_kappa_DPC_FS25_RFE\": df_res_kappa_DPC_FS25_RFE,\n",
    "    \"df_res_kappa_Mix_FS25_RFE\": df_res_kappa_Mix_FS25_RFE\n",
    "}\n",
    "\n",
    "datasets_RFE = {}\n",
    "\n",
    "for dataset_name, dataset in dicc_RFE.items():\n",
    "    datasets_RFE[dataset_name] = remove(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm1qW5F_Za_2",
    "outputId": "3ceb932d-3a56-4511-887a-dac32bd30cdc"
   },
   "outputs": [],
   "source": [
    "# Call Shapiro-Wilks function for each data set\n",
    "\n",
    "for dataset_name, dataset in datasets_RFE.items():\n",
    "    shapiro_test(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CH7oJ2FhZuiN",
    "outputId": "848342f1-8f13-43de-bb1e-5ec6d0ff9949"
   },
   "outputs": [],
   "source": [
    "# QQplot\n",
    "\n",
    "for dataset_name, dataset in datasets_RFE.items():\n",
    "    assess_normality(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySs885kVaF11"
   },
   "outputs": [],
   "source": [
    "# ANOVA\n",
    "\n",
    "norm_dicc_RFE = {\n",
    "    \"df_res_kappa_AAC_RFE\": df_res_kappa_AAC_RFE,\n",
    "    \"df_res_kappa_DPC_RFE\": df_res_kappa_DPC_RFE,\n",
    "    \"df_res_kappa_AAC_FS50_RFE\": df_res_kappa_AAC_FS50_RFE,\n",
    "    \"df_res_kappa_Mix_FS50_RFE\": df_res_kappa_Mix_FS50_RFE,\n",
    "    \"df_res_kappa_AAC_FS25_RFE\": df_res_kappa_AAC_FS25_RFE,\n",
    "    \"df_res_kappa_DPC_FS25_RFE\": df_res_kappa_DPC_FS25_RFE,\n",
    "}\n",
    "\n",
    "norm_datasets_RFE = {}\n",
    "\n",
    "for dataset_name, dataset in norm_dicc_RFE.items():\n",
    "    norm_datasets_RFE[dataset_name] = remove(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpFTYurTaMeo",
    "outputId": "645f4fd2-add7-447f-ec25-737726d145d9"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in norm_datasets_RFE.items():\n",
    "    anova(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpfKXkg9jw1e"
   },
   "outputs": [],
   "source": [
    "# Kruskall Wallis\n",
    "\n",
    "not_norm_dicc_RFE = {\n",
    "    \"df_res_kappa_Mix_RFE\": df_res_kappa_Mix_RFE,\n",
    "    \"df_res_kappa_DPC_FS50_RFE\": df_res_kappa_DPC_FS50_RFE,\n",
    "    \"df_res_kappa_Mix_FS25_RFE\": df_res_kappa_Mix_FS25_RFE\n",
    "}\n",
    "\n",
    "not_norm_datasets_RFE = {}\n",
    "\n",
    "for dataset_name, dataset in not_norm_dicc.items():\n",
    "    not_norm_datasets_RFE[dataset_name] = remove(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9yaP_twkoj4",
    "outputId": "b5d3eda9-71e3-4da9-c3d5-61b940e914b2"
   },
   "outputs": [],
   "source": [
    "for dataset_name, dataset in not_norm_datasets_RFE.items():\n",
    "    kruskal_w(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zdrdUOialDzf",
    "outputId": "4fc7cf44-50d4-4d72-eb5e-402e53ca3252"
   },
   "outputs": [],
   "source": [
    "# Tukey\n",
    "\n",
    "for dataset_name, dataset in datasets_RFE.items():\n",
    "    tukey_test(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TanK_IP1SnB3"
   },
   "source": [
    "### Statistical analysis\n",
    "### For all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3DgDUBTlpi0",
    "outputId": "3ed628b5-f374-4d7b-91cf-74cc745287a7"
   },
   "outputs": [],
   "source": [
    "kappa_all_datasets = [df_res_kappa_AAC_RFE, df_res_kappa_DPC_RFE, df_res_kappa_Mix_RFE, df_res_kappa_AAC_FS50_RFE, df_res_kappa_DPC_FS50_RFE, df_res_kappa_Mix_FS50_RFE, df_res_kappa_AAC_FS25_RFE, df_res_kappa_DPC_FS25_RFE, df_res_kappa_Mix_FS25_RFE]\n",
    "dataframe_names = ['df_res_kappa_AAC_RFE', 'df_res_kappa_DPC_RFE', 'df_res_kappa_Mix_RFE', 'df_res_kappa_AAC_FS50_RFE', 'df_res_kappa_DPC_FS50_RFE', 'df_res_kappa_Mix_FS50_RFE', 'df_res_kappa_AAC_FS25_RFE', 'df_res_kappa_DPC_FS25_RFE', 'df_res_kappa_Mix_FS25_RFE']\n",
    "\n",
    "final_df_RFE = NB_columns(kappa_all_datasets, dataframe_names)\n",
    "print(final_df_RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-G-qqiZmciO",
    "outputId": "8ba21c35-b5a3-4adf-8374-f650a29508ce"
   },
   "outputs": [],
   "source": [
    "# one-dimensional array\n",
    "kappa_data = final_df_RFE.values.flatten()\n",
    "\n",
    "# Shapiro-Wilk\n",
    "statistic, p_value = shapiro(kappa_data)\n",
    "\n",
    "# results\n",
    "print(\"Statistical:\", statistic)\n",
    "print(\"P value:\", p_value)\n",
    "print()\n",
    "\n",
    "if p_value < 0.05:\n",
    "  print(\"Shapiro-Wilk test rejects the null hypothesis.\")\n",
    "  print(\"The NB Dataset DOES NOT FOLLOWS a normal distribution.\")\n",
    "\n",
    "else:\n",
    "  print(\"Shapiro-Wilk test does not reject the null hypothesis.\")\n",
    "  print(\"The NB Dataset FOLLOWS a normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIJZquQ0mx5d",
    "outputId": "e813d691-9458-45ea-c31e-8a51cc694290"
   },
   "outputs": [],
   "source": [
    "# ANOVA\n",
    "anova(final_df_RFE, 'NB Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBa6pdGZmynb",
    "outputId": "2831f450-15c6-4b6f-e9c1-929439dd688c"
   },
   "outputs": [],
   "source": [
    "# Levene's test\n",
    "levene_test(final_df_RFE, 'NB Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QfPKa0e2m_HY",
    "outputId": "1e7792ed-dfd0-491e-be87-d36906b524a7"
   },
   "outputs": [],
   "source": [
    "#Tukey's test\n",
    "tukey_test(final_df_RFE, 'DB Dataset')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rtZ9cc-Z9X_a",
    "_Z9xSsRT9oOv",
    "my4vKoxD9yOC",
    "WMBuSxdqI60s",
    "_ttMkSpjtGvd",
    "mgUtGT6zEKjY",
    "O-R8LqQd2K2g",
    "Rzijyjy3D60D",
    "59VJ1xDo_v62",
    "RMjxzaGkHrHk",
    "38pAQmiFAKFZ",
    "wCsSLk_kK358",
    "SW-xl-vYAFs5",
    "uxWzJG6G_dDu",
    "PAI4pE8ZbmiV",
    "XVmGROwoSvJ4",
    "plecwDZvZfc7",
    "NCl-jj-vfOZd",
    "BizatuYFRxiy",
    "TanK_IP1SnB3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
