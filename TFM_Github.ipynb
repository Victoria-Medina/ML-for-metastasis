{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5exG6uOvsgs"
      },
      "source": [
        "#ML for metastasis\n",
        "\n",
        "ML classifiers for metastatic vs non-metastatic protein sequences.\n",
        "\n",
        "1.   Get fasta sequences and convert them into TXT (metastatic and non-metastatic proteins)\n",
        "2.   Calculate molecular descriptors (dataset for ML)\n",
        "3.   Build ML classifiers for metastatic and non-metastatic protein sequences (split dataset, build models, feature selection, model comparison)\n",
        "4. Statistical analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpM-edgfVeSF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOjyPjWYdJLv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDZyZyscyBRz"
      },
      "outputs": [],
      "source": [
        "dsPath = # set path to dataset subfolder in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmzg6UymdsRZ"
      },
      "outputs": [],
      "source": [
        "# Print content in drive to check if it is OK\n",
        "for filename in os.listdir(dsPath):\n",
        "  print(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHnzS7OrbyNa"
      },
      "outputs": [],
      "source": [
        "resPath = # set path to results subfolder in drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtZ9cc-Z9X_a"
      },
      "source": [
        "##Convert FASTA to CSV format\n",
        "\n",
        "Read all the sequences for metastatic and non-metastatic proteins and convert in ProteinName, Sequence format as CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AF-xaN9eWvfB"
      },
      "outputs": [],
      "source": [
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VX9icrY_VeSN"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VzMpDONew16P"
      },
      "outputs": [],
      "source": [
        "# Define a function to read fasta sequences one at a time\n",
        "def fasta_generator(input_file):\n",
        "    with open(input_file, 'r') as fasta_file:\n",
        "        for record in SeqIO.parse(fasta_file, 'fasta'):\n",
        "            yield record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dmn_nTvr0fw1"
      },
      "outputs": [],
      "source": [
        "# Define 2 lists with protein name\n",
        "metastasis_POS = []  # metastatic proteins\n",
        "metastasis_NEG = []  # non-metastatic proteins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZRKPWe_pvy1L"
      },
      "outputs": [],
      "source": [
        "# Get fasta sequences for metastasis_POS proteins\n",
        "# Define fasta file to read and csv file to write the protein name and the sequences\n",
        "inFile  = dsPath+'MODELO_1_POSITIVE_metastasis.fasta' # to read\n",
        "outFile = dsPath+'metastasis_POS.csv'       # to write\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(outFile, 'w') as out_file:\n",
        "  out_file.write(f'ProteinDescription,Sequence\\n')  # write the header\n",
        "  # Iterate over each fasta sequence using the generator\n",
        "  for fasta in fasta_generator(inFile):\n",
        "      name = fasta.id\n",
        "      sequence = str(fasta.seq)               # convert the sequence to a string\n",
        "      out_file.write(f'{name},{sequence}\\n')  # write only the sequence to the output file\n",
        "      metastasis_POS.append(name+\",\"+sequence)           # add the sequence to a list TFs\n",
        "\n",
        "out_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HNaL6QWN0-YK"
      },
      "outputs": [],
      "source": [
        "# Checking metastasis_POS list\n",
        "print(\"No of metastasis_POS sequences:\", len(metastasis_POS))\n",
        "# Print first sequence in metastasis_POS to check if it is OK\n",
        "print(\"First metastasis_POS sequence:\\n\"+metastasis_POS[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D_NB8JhYybs9"
      },
      "outputs": [],
      "source": [
        "# Get fasta sequences for metastasis_NEG proteins\n",
        "# Define fasta file to read and csv file to write the protein names and sequences\n",
        "inFile  = dsPath+'MODELO_1_NEGATIVE_metastasis.fasta'\n",
        "outFile = dsPath+'metastasis_NEG.csv'\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(outFile, 'w') as out_file:\n",
        "  out_file.write(f'ProteinDescription,Sequence\\n')  # write the header\n",
        "  # Iterate over each fasta sequence using the generator\n",
        "  for fasta in fasta_generator(inFile):\n",
        "      name = fasta.id\n",
        "      sequence = str(fasta.seq)               # convert the sequence to a string\n",
        "      out_file.write(f'{name},{sequence}\\n')  # write only the sequence to the output file\n",
        "      metastasis_NEG.append(name+\",\"+sequence)        # add the sequence to a list\n",
        "\n",
        "out_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3bMkqMvU0Vq-"
      },
      "outputs": [],
      "source": [
        "# Checking metastasis_NEG list\n",
        "print(\"No of metastasis_NEG sequences:\", len(metastasis_NEG))\n",
        "# Print first sequence to check if it is OK\n",
        "print(\"First metastasis_NEG sequence:\\n\"+metastasis_NEG[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z9xSsRT9oOv"
      },
      "source": [
        "##Check for common sequences in metastasis_POS and metastasis_NEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-2_HsFz2Aj6"
      },
      "outputs": [],
      "source": [
        "# List with errors\n",
        "errors = []\n",
        "\n",
        "# Check if we have the same sequence in both lists\n",
        "with open(dsPath+\"Errors.csv\", 'w') as out_file:\n",
        "  out_file.write(f'ErrNo,metastasis_POS,metastasis_NEG,metastasis_POS_seq, metastasis_NEG_seq\\n')\n",
        "  n=0\n",
        "  for idmPOS in range(len(metastasis_POS)):\n",
        "    name_metastasis_POS, seq_metastasis_POS = metastasis_POS[idmPOS].split(',')\n",
        "    for idmNEG in range(len(metastasis_NEG)):\n",
        "      name_metastasis_NEG, seq_metastasis_NEG = metastasis_NEG[idmNEG].split(',')\n",
        "      if (name_metastasis_POS == name_metastasis_NEG):\n",
        "        n=n+1\n",
        "        print(n, name_metastasis_POS, name_metastasis_NEG, seq_metastasis_POS, seq_metastasis_NEG)\n",
        "        out_file.write(f'{n},{name_metastasis_POS},{name_metastasis_NEG},{seq_metastasis_POS},{seq_metastasis_NEG}\\n')\n",
        "        errors.append(name_metastasis_NEG+\",\"+seq_metastasis_NEG)        # add the sequence to a list\n",
        "        continue\n",
        "  if n==0: print(\"No errors!\")\n",
        "  else:\n",
        "    print(errors)\n",
        "out_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my4vKoxD9yOC"
      },
      "source": [
        "##Get the list of sequences to use for descriptors calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPW3V41NF_7N"
      },
      "outputs": [],
      "source": [
        "# Get only the lists of ONLY the sequences\n",
        "listmPOS = []\n",
        "for seqPOS in metastasis_POS:\n",
        "    name_seqPOS, seq_seqPOS = seqPOS.split(',')\n",
        "    listmPOS.append(seq_seqPOS)\n",
        "\n",
        "# Get only the lists of ONLY the sequences\n",
        "listmNEG = []\n",
        "for seqNEG in metastasis_NEG:\n",
        "    name_seqNEG, seq_seqNEG = seqNEG.split(',')\n",
        "    listmNEG.append(seq_seqNEG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eJlu4tUG78O"
      },
      "outputs": [],
      "source": [
        "print(\"The study will use\", len(listmPOS),\"metastasic sequences vs.\", len(listmNEG), \"non metastasic sequences.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMBuSxdqI60s"
      },
      "source": [
        "##Molecular descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q3uTsLzMG2s"
      },
      "outputs": [],
      "source": [
        "# Install package for protein molecular descriptors\n",
        "!pip install propy3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DePTHZg-UD9l"
      },
      "outputs": [],
      "source": [
        "from propy import PyPro\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ttMkSpjtGvd"
      },
      "source": [
        "###Descriptors from list (metastasis_POS and metastasis_NEG) to dataframes (AAC, DPC, Mix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTp4_slP7v5"
      },
      "outputs": [],
      "source": [
        "def to_dataframe(list_sequences, is_POS):\n",
        "    data_AAC = []  # list with AAC descriptors\n",
        "    data_DPC = []  # list with DPC descriptors\n",
        "    data_Mix = []  # list with Mix descriptors\n",
        "\n",
        "    for sequence in list_sequences:  # for each sequence of the list\n",
        "        DesObject = PyPro.GetProDes(sequence)  # create an object for descriptors\n",
        "        amino_acid_composition = DesObject.GetAAComp()  # calculate amino_acid_composition (AAC) descriptors (dictionary)\n",
        "        dipeptide_composition = DesObject.GetDPComp()  # calculate dipeptide_composition (DPC) descriptors (dictionary)\n",
        "        data_AAC.append(list(amino_acid_composition.values()))  # add AAC descriptors to list data_AAC\n",
        "        data_DPC.append(list(dipeptide_composition.values()))  # add DPC descriptors to list data_DPC\n",
        "        data_Mix.append(list(amino_acid_composition.values()) + list(dipeptide_composition.values()))  # add both AAC and DPC descriptors (mix) to list data_Mix\n",
        "\n",
        "    # create 3 dataframes, one for each set of descriptors: AAC, DPC and Mix,\n",
        "    # using the descriptors values from the previous lists and the header with the descriptors names (dictionary keys)\n",
        "    # amino_acid_composition, dipeptide_composition are dictionaries\n",
        "    columns_AAC = list(amino_acid_composition.keys())\n",
        "    columns_DPC = list(dipeptide_composition.keys())\n",
        "\n",
        "    df_AAC = pd.DataFrame(data_AAC, columns=columns_AAC)\n",
        "    df_DPC = pd.DataFrame(data_DPC, columns=columns_DPC)\n",
        "    df_Mix = pd.DataFrame(data_Mix, columns=columns_AAC + columns_DPC)\n",
        "\n",
        "    # add a new column as the last one with the class (metastasis_POS = 1; metastasis_NEG = 0)\n",
        "    df_AAC['Class'] = 1 if is_POS else 0\n",
        "    df_DPC['Class'] = 1 if is_POS else 0\n",
        "    df_Mix['Class'] = 1 if is_POS else 0\n",
        "\n",
        "    return df_AAC, df_DPC, df_Mix\n",
        "\n",
        "# listmPOS\n",
        "df_AAC_mPOS, df_DPC_mPOS, df_Mix_mPOS = to_dataframe(listmPOS, is_POS=True)\n",
        "\n",
        "# listmNEG\n",
        "df_AAC_mNEG, df_DPC_mNEG, df_Mix_mNEG = to_dataframe(listmNEG, is_POS=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lIrPcFJR6fM"
      },
      "outputs": [],
      "source": [
        "# Checking dataframes\n",
        "\n",
        "# Metastasis_POS\n",
        "#df_AAC_mPOS\n",
        "#df_DPC_mPOS\n",
        "#df_Mix_mPOS\n",
        "\n",
        "# Metastasis_NEG\n",
        "#df_AAC_mNEG\n",
        "#df_DPC_mNEG\n",
        "#df_Mix_mNEG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUtGT6zEKjY"
      },
      "source": [
        "##Datasets\n",
        "\n",
        "We will create different datasets using the previous dataframes with descriptors for metastasis_POS and metastasis_NEG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-R8LqQd2K2g"
      },
      "source": [
        "### Datasets with all descriptors (no feature selection, without normalization)\n",
        "\n",
        "We have 6 dataframes with descriptors for metastasis_POS and metastasis_NEG:\n",
        "\n",
        "*   for metastasis_POS: df_AAC_mPOS, df_DPC_mPOS, df_Mix_mPOS\n",
        "*   for metastasis_NEG: df_AAC_mNEG, df_DPC_mNEG, df_Mix_mNEG\n",
        "\n",
        "We will mix descriptors for metastasis_POS and metastasis_NEG for each subset of descriptors: AAC, DPC and Mix (by merging the correspondent dataframes). We will obtain datasets: ds_AAC, ds_DPC, ds_Mix as dataframes and CSV files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IFRcooMaWtj"
      },
      "outputs": [],
      "source": [
        "ds_AAC = pd.concat([df_AAC_mPOS, df_AAC_mNEG], axis=0) # dataset for AAC (AAC descriptors for metastasis_POS and metastasis_NEG)\n",
        "ds_DPC = pd.concat([df_DPC_mPOS, df_DPC_mNEG], axis=0) # dataset for DPC (DPC descriptors for metastasis_POS and metastasis_NEG)\n",
        "ds_Mix = pd.concat([df_Mix_mPOS, df_Mix_mNEG], axis=0) # dataset for Mix (AAC and DPC descriptors for metastasis_POS and metastasis_NEG)\n",
        "\n",
        "# Save the datasets on files (in your Gdrive folder)\n",
        "# These are the datasets with all the descriptors, without feature selection, without data normalization!\n",
        "ds_AAC.to_csv(dsPath+'dsAAC.csv', index=False)\n",
        "ds_DPC.to_csv(dsPath+'dsDPC.csv', index=False)\n",
        "ds_Mix.to_csv(dsPath+'dsMix.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTiyw8Ftb3Fh"
      },
      "outputs": [],
      "source": [
        "# Checking dataframes\n",
        "#ds_AAC\n",
        "#ds_DPC\n",
        "#ds_Mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PwIvuWV-KBG"
      },
      "source": [
        "The datasets from dsAAC.csv, dsDPC.csv and dsMix.csv will be used in feature selections and directly to build ML models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzijyjy3D60D"
      },
      "source": [
        "###Dataset description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDnzafkYDzIL"
      },
      "outputs": [],
      "source": [
        "data = ds_DPC\n",
        "\n",
        "class_column = data.columns[-1]\n",
        "class_count = data[class_column].value_counts()\n",
        "\n",
        "plt.figure(figsize=(4, 5))\n",
        "\n",
        "class_count.plot(kind='bar', color=['#87CEEB', '#98FB98'], width=0.35)\n",
        "\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Amount of proteins')\n",
        "plt.title('Data Distribution')\n",
        "\n",
        "plt.xticks(ticks=[0, 1], labels=['Non-metastatic proteins', 'Metastatic proteins'], rotation=0, wrap=True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59VJ1xDo_v62"
      },
      "source": [
        "###Normalized datasets of AAC, DPC and Mix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8MDaglD_00h"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AntFmoEeoNK"
      },
      "outputs": [],
      "source": [
        "# Normalises the datasets between 0 and 1\n",
        "\n",
        "def normalize(ds, ds_name, ds_path):\n",
        "    # create the normalized dataframe as copy of the raw dataset\n",
        "    ds_norm = ds.copy()\n",
        "\n",
        "    # create a scaler object\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # select all columns except the last one (excluding the class)\n",
        "    cols_to_scale = ds_norm.columns[:-1]\n",
        "\n",
        "    # normalize the selected columns\n",
        "    ds_norm[cols_to_scale] = scaler.fit_transform(ds_norm[cols_to_scale])\n",
        "\n",
        "    # save the scaler for future predictions\n",
        "    scaler_file = ds_path + 'ds{}_norm_scalerMinMax.pkl'.format(ds_name)\n",
        "    joblib.dump(scaler, scaler_file)\n",
        "\n",
        "    # save the normalized dataset as CSV file\n",
        "    ds_norm.to_csv(ds_path + 'ds{}_norm.csv'.format(ds_name), index=False)\n",
        "\n",
        "    return ds_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVmuRrX0ezKi"
      },
      "outputs": [],
      "source": [
        "# AAC dataset\n",
        "ds_AAC_norm = normalize(ds_AAC, 'AAC', dsPath)\n",
        "\n",
        "# DPC dataset\n",
        "ds_DPC_norm = normalize(ds_DPC, 'DPC', dsPath)\n",
        "\n",
        "# Mix dataset\n",
        "ds_Mix_norm = normalize(ds_Mix, 'Mix', dsPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um0Ig-jXe6sR"
      },
      "outputs": [],
      "source": [
        "# Checking the normalized datasets\n",
        "#ds_AAC_norm\n",
        "#ds_DPC_norm\n",
        "#ds_Mix_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMjxzaGkHrHk"
      },
      "source": [
        "## Univariate feature selection\n",
        "\n",
        "The normalized datasets for AAC, DPC and Mix will be used to build ML models and for selection features. This moment, we have 3 datasets (normalized datasets with pool features for AAC, DPC and Mix).\n",
        "\n",
        "We will create 3 new datasets with the best features for AAC, DPC and Mix descriptors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIOjVa5JCcWy"
      },
      "outputs": [],
      "source": [
        "# Function to obtain input descriptors and output class as arrays, and the list with the names of the descriptors\n",
        "\n",
        "def getDataFromDataFrame(df, OutVar='Class'):\n",
        "    # get X, Y data and column names from df\n",
        "    print('\\n-> Get X & Y data, Features list')\n",
        "    print('Shape', df.shape)\n",
        "\n",
        "    # select X and Y\n",
        "    ds_y = df[OutVar]\n",
        "    ds_X = df.drop(OutVar,axis = 1)\n",
        "    Xdata = ds_X.values # get values of features\n",
        "    Ydata = ds_y.values # get output values\n",
        "\n",
        "    print('Shape X data:', Xdata.shape)\n",
        "    print('Shape Y data:', Ydata.shape)\n",
        "    print('Done!')\n",
        "\n",
        "    # return data for X and Y, feature names as list\n",
        "    return (Xdata, Ydata, list(ds_X.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccrMfqq1KAdz"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "\n",
        "def FeatureSelection(df,label,nFeats=1):\n",
        "    if nFeats == 0:\n",
        "        print(\"\\n NO feature selection\")\n",
        "        return df\n",
        "\n",
        "    # Get separated info\n",
        "    Xdata, Ydata, Features = getDataFromDataFrame(df)  # out var = Class\n",
        "\n",
        "    # Feature selection\n",
        "    print('\\n-> Univariate Feature selection')\n",
        "    print('Initial columns:', list(df.columns))\n",
        "    selector= SelectKBest(f_classif, k=nFeats)  # you can select other feature selection\n",
        "    Xdata = selector.fit_transform(Xdata, Ydata)  # select the features\n",
        "\n",
        "    # Get the selected features\n",
        "    SelFeatures = []\n",
        "    for i in selector.get_support(indices=True):\n",
        "        SelFeatures.append(Features[i])\n",
        "\n",
        "    # Create the new dataframe with selected features\n",
        "    df = pd.DataFrame(Xdata,columns=SelFeatures)\n",
        "    df['Class'] = Ydata  # add class column\n",
        "    print('Final columns:', list(df.columns))\n",
        "\n",
        "    # Save selected feature dataset\n",
        "    selectFile = dsPath+'ds'+label+'.normFS('+str(nFeats)+').csv'  # dataset with selected features\n",
        "    print('* Save selected features dataset:', selectFile)\n",
        "    df.to_csv(selectFile, index=False)\n",
        "\n",
        "    print('Done!')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToB2Ns3xiWaR"
      },
      "source": [
        "###50% of descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UY1B8rHiaKy"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection for AAC using the normalized dataset\n",
        "ds_AAC_normFS50 = FeatureSelection(ds_AAC_norm,\"AAC\",nFeats=10) # select the best 10 features (10/20)\n",
        "ds_AAC_normFS50 # check the feature selected dataset for AAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tiJIXqEimuV"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection for DPC using the normalized dataset\n",
        "ds_DPC_normFS50 = FeatureSelection(ds_DPC_norm,\"DPC\",nFeats=200) # select the best 200 features (200/400)\n",
        "ds_DPC_normFS50 # check the feature selected dataset for DPC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7Q2m-IKiv-z"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection for Mix using the normalized dataset\n",
        "ds_Mix_normFS50 = FeatureSelection(ds_Mix_norm,\"Mix\",nFeats=210) # select the best 210 features (210/420)\n",
        "ds_Mix_normFS50 # check the feature selected dataset for Mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BBd567XgrWn"
      },
      "source": [
        "###25% of descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycKIsYXZJY5A"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection for AAC using the normalized dataset\n",
        "ds_AAC_normFS25 = FeatureSelection(ds_AAC_norm,\"AAC\",nFeats=5) # select the best 5 features (5/20)\n",
        "ds_AAC_normFS25 # check the feature selected dataset for AAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I97ReeKyM0LN"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection for DPC using the normalized dataset\n",
        "ds_DPC_normFS25 = FeatureSelection(ds_DPC_norm,\"DPC\",nFeats=100) # select the best 100 features (100/400)\n",
        "ds_DPC_normFS25 # check the feature selected dataset for DPC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJP9scM2OLm2"
      },
      "outputs": [],
      "source": [
        "# Univariate feature selection for Mix using the normalized dataset\n",
        "ds_Mix_normFS25 = FeatureSelection(ds_Mix_norm,\"Mix\",nFeats=105) # select the best 105 features (105/420)\n",
        "ds_Mix_normFS25 # check the feature selected dataset for Mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mEgJugyOizV"
      },
      "source": [
        "### ML classifiers for metastasic vs non-metastasic protein sequences\n",
        "\n",
        "We have 9 datasets to use with different ML classifier:\n",
        "*   3 normalized datasets with all descriptors: ds_AAC_norm, ds_DPC_norm, ds_Mix_norm\n",
        "*  3 dataset with 50% of the best features selected from the previous datasets: ds_AAC_normFS50 (only 10 features from 20), ds_DPC_normFS50 (only 200 features from 400), ds_Mix_normFS50 (only 210 features from 420).\n",
        "*   3 dataset with 25% of the best features selected from the previous datasets: ds_AAC_normFS25 (only 5 features from 20), ds_DPC_normFS25 (only 100 features from 400), ds_Mix_normFS25 (only 105 features from 420).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulyyU534MzMB"
      },
      "source": [
        "###Functions for ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1xiKqCeco2X"
      },
      "outputs": [],
      "source": [
        "nfold = 10 # number of fold-CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw5Kqe9nWHEl"
      },
      "outputs": [],
      "source": [
        "# Create a function that will build ML models for one dataset\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, cohen_kappa_score, recall_score, precision_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def MLOuterCV(Xdata, Ydata, folds, seed=2024):\n",
        "    # define classifiers labels in results\n",
        "    names = ['NB', 'KNN', 'LDA', 'SVM', 'SVMrbf', 'LR', 'MLP', 'DT', 'RF', 'XGB']\n",
        "\n",
        "    classifiers = [GaussianNB(),\n",
        "                   KNeighborsClassifier(5),\n",
        "                   LinearDiscriminantAnalysis(solver='svd'),  # no random_state\n",
        "                   SVC(kernel=\"linear\", random_state=seed, gamma='scale'),\n",
        "                   SVC(kernel='rbf', random_state=seed, gamma='scale'),\n",
        "                   LogisticRegression(solver='lbfgs', random_state=seed),\n",
        "                   MLPClassifier(random_state=seed, max_iter=50000, shuffle=False),\n",
        "                   DecisionTreeClassifier(random_state=seed),\n",
        "                   RandomForestClassifier(n_jobs=-1, random_state=seed),\n",
        "                   XGBClassifier(n_jobs=-1, seed=seed)\n",
        "                   ]\n",
        "\n",
        "    # results dataframe: each column for a classifier\n",
        "    df_res_auroc = pd.DataFrame(columns=names, dtype=object)\n",
        "    df_res_f1 = pd.DataFrame(columns=names, dtype=object)\n",
        "    df_res_kappa = pd.DataFrame(columns=names, dtype=object)\n",
        "    df_res_recall = pd.DataFrame(columns=names, dtype=object)\n",
        "    df_res_precision = pd.DataFrame(columns=names, dtype=object)\n",
        "\n",
        "    # build each classifier\n",
        "    print('* Building ' + str(folds) + '-fold CV for ' + str(len(names)) + ' classifiers:', str(names))\n",
        "    total = time.time()\n",
        "\n",
        "    # define a fold-CV for all the classifier\n",
        "    outer_cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
        "\n",
        "    print('ML method, AUROC Mean, AUROC SD, F1 Mean, F1 SD, Kappa Mean, Kappa SD, Recall Mean, Recall SD, Precision Mean, Precision SD, Time (min)')\n",
        "\n",
        "    for name, clf in zip(names, classifiers):\n",
        "        start = time.time()\n",
        "\n",
        "        # evaluate pipeline\n",
        "        scores_auroc = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='roc_auc', n_jobs=-1)\n",
        "        scores_f1 = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='f1', n_jobs=-1)\n",
        "        scores_kappa = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
        "        scores_recall = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='recall', n_jobs=-1)\n",
        "        scores_precision = cross_val_score(clf, Xdata, Ydata, cv=outer_cv, scoring='precision', n_jobs=-1)\n",
        "\n",
        "        df_res_auroc[name] = scores_auroc\n",
        "        df_res_f1[name] = scores_f1\n",
        "        df_res_kappa[name] = scores_kappa\n",
        "        df_res_recall[name] = scores_recall\n",
        "        df_res_precision[name] = scores_precision\n",
        "\n",
        "        results_string = ('%s, %0.3f, %0.4f, %0.3f, %0.4f, %0.3f, %0.4f, %0.3f, %0.4f, %0.3f, %0.4f, %0.1f' %\n",
        "                        (name, scores_auroc.mean(), scores_auroc.std(),\n",
        "                          scores_f1.mean(), scores_f1.std(),\n",
        "                          scores_kappa.mean(), scores_kappa.std(),\n",
        "                          scores_recall.mean(), scores_recall.std(),\n",
        "                          scores_precision.mean(), scores_precision.std(),\n",
        "                          (time.time() - start) / 60))\n",
        "        print(results_string)\n",
        "\n",
        "    print('Total time:', (time.time() - total) / 60, ' mins')\n",
        "    return [df_res_auroc, df_res_f1, df_res_kappa, df_res_recall, df_res_precision]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSvD-dz0FQDu"
      },
      "outputs": [],
      "source": [
        "# Function to build ML models, write the results plot box plots for a dataframe\n",
        "\n",
        "def MLmodels(df, df_fold, nfold, label=\"X\", label_y=\"Y\"):\n",
        "    df_results = None\n",
        "    df_fold['Dataset'] = label\n",
        "    df_fold['folds'] = nfold\n",
        "\n",
        "    # add each result to a summary dataframe\n",
        "    df_results = pd.concat([df_results,df_fold])\n",
        "    summaryFile = resPath+'ML_'+label+'_'+label_y+'.csv' # ML metrics results\n",
        "    boxplotFile = resPath+'ML_'+label+'_'+label_y+'.png' # box plot of the metrics\n",
        "\n",
        "    # save all results\n",
        "    print('\\n==>> Saving summary', summaryFile)\n",
        "    df_results.to_csv(summaryFile, index=False)\n",
        "\n",
        "    # save boxplot\n",
        "    classifierNames = list(df_results.columns)\n",
        "    classifierNames.remove('Dataset')\n",
        "    classifierNames.remove('folds')\n",
        "\n",
        "    foldTypes=[nfold]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.clf()\n",
        "    print('==> Fold =', nfold)\n",
        "    grouped = df_results[df_results['folds']==nfold].drop(['folds'], axis=1).groupby('Dataset')\n",
        "    #grouped.boxplot(figsize=(16,12), return_type='axes')\n",
        "    grouped.boxplot(return_type='axes')\n",
        "    plt.title(\"\")\n",
        "    #plt.xlabel(\"Machine Learning methods for \"+label,size=18)\n",
        "    #plt.ylabel(\"AUROC (\"+str(nfold)+\"-fold CV)\",size=18)\n",
        "    plt.xlabel(\"Machine Learning methods for \"+ label)\n",
        "    plt.ylabel(label_y + \"(\"+str(nfold)+\"-fold CV)\")\n",
        "    #plt.tick_params(labelsize=14)\n",
        "    plt.ylim(0,1.0)\n",
        "    #plt.savefig(boxplotFile, dpi=1200)\n",
        "    plt.savefig(boxplotFile)\n",
        "    plt.show()\n",
        "\n",
        "    df_results\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZinYbt4hErQ"
      },
      "source": [
        "### ML models and box plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-PtNX70Ww91"
      },
      "outputs": [],
      "source": [
        "# ML for AAC normalized dataset with all descriptors (no feature selection)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_norm)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_AAC, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_AAC_norm, df_res_auroc, nfold, label=\"AAC_norm\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_AAC_norm, df_res_f1, nfold, label=\"AAC_norm\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_AAC_norm, df_res_kappa_AAC, nfold, label=\"AAC_norm\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_AAC_norm, df_res_recall, nfold, label=\"AAC_norm\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_AAC_norm, df_res_precision, nfold, label=\"AAC_norm\", label_y=\"Precision\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBKFFxdUOW-m"
      },
      "outputs": [],
      "source": [
        "# ML for DPC normalized dataset with all descriptors (no feature selection)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_norm)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_DPC, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_DPC_norm, df_res_auroc, nfold, label=\"DPC_norm\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_DPC_norm, df_res_f1, nfold, label=\"DPC_norm\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_DPC_norm, df_res_kappa_DPC, nfold, label=\"DPC_norm\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_DPC_norm, df_res_recall, nfold, label=\"DPC_norm\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_DPC_norm, df_res_precision, nfold, label=\"DPC_norm\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kj_6O90gBt-"
      },
      "outputs": [],
      "source": [
        "# ML for Mix normalized dataset with all descriptors (no feature selection)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_norm)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_Mix, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_Mix_norm, df_res_auroc, nfold, label=\"Mix_norm\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_Mix_norm, df_res_f1, nfold, label=\"Mix_norm\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_Mix_norm, df_res_kappa_Mix, nfold, label=\"Mix_norm\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_Mix_norm, df_res_recall, nfold, label=\"Mix_norm\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_Mix_norm, df_res_precision, nfold, label=\"Mix_norm\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF2M9zLoQ1Jk"
      },
      "source": [
        "###50% of descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBeWCEGsgIyY"
      },
      "outputs": [],
      "source": [
        "# ML for AAC normalized dataset with selected features\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS50)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS50, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_AAC_normFS50, df_res_auroc, nfold, label=\"AAC_normFS50\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_AAC_normFS50, df_res_f1, nfold, label=\"AAC_normFS50\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_AAC_normFS50, df_res_kappa_AAC_FS50, nfold, label=\"AAC_normFS50\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_AAC_normFS50, df_res_recall, nfold, label=\"AAC_normFS50\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_AAC_normFS50, df_res_precision, nfold, label=\"AAC_normFS50\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxFGBnIOgQFC"
      },
      "outputs": [],
      "source": [
        "# ML for DPC normalized dataset with selected features\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS50)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS50, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_DPC_normFS50, df_res_auroc, nfold, label=\"DPC_normFS50\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_DPC_normFS50, df_res_f1, nfold, label=\"DPC_normFS50\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_DPC_normFS50, df_res_kappa_DPC_FS50, nfold, label=\"DPC_normFS50\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_DPC_normFS50, df_res_recall, nfold, label=\"DPC_normFS50\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_DPC_normFS50, df_res_precision, nfold, label=\"DPC_normFS50\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipW-LnqIgUDZ"
      },
      "outputs": [],
      "source": [
        "# ML for Mix normalized dataset with selected features\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS50)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS50, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_Mix_normFS50, df_res_auroc, nfold, label=\"Mix_normFS50\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_Mix_normFS50, df_res_f1, nfold, label=\"Mix_normFS50\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_Mix_normFS50, df_res_kappa_Mix_FS50, nfold, label=\"Mix_normFS50\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_Mix_normFS50, df_res_recall, nfold, label=\"Mix_normFS50\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_Mix_normFS50, df_res_precision, nfold, label=\"Mix_normFS50\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqVLwnnLRGXJ"
      },
      "source": [
        "###25% of descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXWCPz6Vga_2"
      },
      "outputs": [],
      "source": [
        "# ML for AAC normalized dataset with selected features\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS25)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS25, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_AAC_normFS25, df_res_auroc, nfold, label=\"AAC_normFS25\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_AAC_normFS25, df_res_f1, nfold, label=\"AAC_normFS25\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_AAC_normFS25, df_res_kappa_AAC_FS25, nfold, label=\"AAC_normFS25\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_AAC_normFS25, df_res_recall, nfold, label=\"AAC_normFS25\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_AAC_normFS25, df_res_precision, nfold, label=\"AAC_normFS25\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tlTkf-WRYqI"
      },
      "outputs": [],
      "source": [
        "# ML for DPC normalized dataset with selected features\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS25)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS25, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_DPC_normFS25, df_res_auroc, nfold, label=\"DPC_normFS25\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_DPC_normFS25, df_res_f1, nfold, label=\"DPC_normFS25\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_DPC_normFS25, df_res_kappa_DPC_FS25, nfold, label=\"DPC_normFS25\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_DPC_normFS25, df_res_recall, nfold, label=\"DPC_normFS25\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_DPC_normFS25, df_res_precision, nfold, label=\"DPC_normFS25\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgxiDnyqRfE_"
      },
      "outputs": [],
      "source": [
        "# ML for Mix normalized dataset with selected features\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS25)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS25, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_Mix_normFS25, df_res_auroc, nfold, label=\"Mix_normFS25\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_Mix_normFS25, df_res_f1, nfold, label=\"Mix_normFS25\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_Mix_normFS25, df_res_kappa_Mix_FS25, nfold, label=\"Mix_normFS25\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_Mix_normFS25, df_res_recall, nfold, label=\"Mix_normFS25\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_Mix_normFS25, df_res_precision, nfold, label=\"Mix_normFS25\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38pAQmiFAKFZ"
      },
      "source": [
        "### Statistical Analysis\n",
        "\n",
        "### For each dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCsSLk_kK358"
      },
      "source": [
        "#### Normality: Shapiro-Wilk and QQ Plot:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYU32uZxfOAr"
      },
      "source": [
        "#### Shapiro-Wilk test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiBNeW01WG_v"
      },
      "outputs": [],
      "source": [
        "# Remove the last two columns from each dataframe\n",
        "\n",
        "dicc = {\n",
        "    \"df_res_kappa_AAC\": df_res_kappa_AAC,\n",
        "    \"df_res_kappa_DPC\": df_res_kappa_DPC,\n",
        "    \"df_res_kappa_Mix\": df_res_kappa_Mix,\n",
        "    \"df_res_kappa_AAC_FS50\": df_res_kappa_AAC_FS50,\n",
        "    \"df_res_kappa_DPC_FS50\": df_res_kappa_DPC_FS50,\n",
        "    \"df_res_kappa_Mix_FS50\": df_res_kappa_Mix_FS50,\n",
        "    \"df_res_kappa_AAC_FS25\": df_res_kappa_AAC_FS25,\n",
        "    \"df_res_kappa_DPC_FS25\": df_res_kappa_DPC_FS25,\n",
        "    \"df_res_kappa_Mix_FS25\": df_res_kappa_Mix_FS25\n",
        "}\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "def remove(df):\n",
        "    return df.iloc[:, :-2]\n",
        "\n",
        "for dataset_name, dataset in dicc.items():\n",
        "    datasets[dataset_name] = remove(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw9er441k9K6"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "def shapiro_test(df_res_kappa, dataset_name):\n",
        "  ''' H0: The null hypothesis states that the data come from a population with a normal distribution.\n",
        "      H1: The alternative hypothesis suggests that the data do not come from a population with a normal distribution.'''\n",
        "\n",
        "  # Shapiro-Wilk\n",
        "  statistic, p_value = shapiro(df_res_kappa)\n",
        "\n",
        "  # Results\n",
        "  if p_value < 0.05:\n",
        "    print(\"Shapiro-Wilk test rejects the null hypothesis.\")\n",
        "    print(\"The dataset \"f\"\\033[1m{dataset_name}\\033[0m DOES NOT FOLLOWS a normal distribution.\")\n",
        "\n",
        "  else:\n",
        "    print(\"Shapiro-Wilk test does not reject the null hypothesis.\")\n",
        "    print(\"The dataset \"f\"\\033[1m{dataset_name}\\033[0m FOLLOWS a normal distribution.\")\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRIj1hoa5tou"
      },
      "outputs": [],
      "source": [
        "# Call Shapiro-Wilks function for each data set\n",
        "\n",
        "for dataset_name, dataset in datasets.items():\n",
        "    shapiro_test(dataset, dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWtNB_z_LH_A"
      },
      "source": [
        "#### QQ Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsEGf7AQLMaG"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def assess_normality(df, dataset_name):\n",
        "\n",
        "  # Calculate row averages and convert to a single column DataFrame\n",
        "  y = df.values.flatten()\n",
        "\n",
        "  # Create a sequence of integers as indexes for the columns\n",
        "  x = range (len(y))\n",
        "\n",
        "  # Fit a linear regression model and obtain the residuals\n",
        "  model = sm.OLS(y, sm.add_constant(x)).fit()\n",
        "  residuals = model.resid\n",
        "\n",
        "  # Plot QQ plot\n",
        "  sm.qqplot(residuals, line='s')\n",
        "  plt.title(f'Normality Assessment of Residuals for {dataset_name}', fontsize=18)\n",
        "  plt.xlabel('Theoretical Quantiles', fontsize=15)\n",
        "  plt.ylabel('Sample Residual Quantiles', fontsize=15)\n",
        "  plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG__Sk9oRH2Z"
      },
      "outputs": [],
      "source": [
        "for dataset_name, dataset in datasets.items():\n",
        "    assess_normality(dataset, dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Levene's test\n",
        "Variance of the classifiers"
      ],
      "metadata": {
        "id": "_QltmnZselby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import levene\n",
        "\n",
        "def levene_test(dataset, dataset_name):\n",
        "\n",
        "  ''' H0: The variances of the classifiers are homogeneous.\n",
        "      H1: At least one of the variances of the classifiers differs from the others.'''\n",
        "\n",
        "  # Levene's test\n",
        "  statistic, p_value = levene(*[dataset[column] for column in dataset.columns])\n",
        "\n",
        "  # Results\n",
        "  print(\"Levene's Test Statistic:\", statistic)\n",
        "  print(\"p-value:\", p_value)\n",
        "\n",
        "  # p-value\n",
        "  if p_value < 0.05:\n",
        "      print(\"Reject the null hypothesis of equal variances.\")\n",
        "      print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE IS at least one classifier whose variance is statistically different from the others.\")\n",
        "\n",
        "  else:\n",
        "      print(\"Does no reject null hypothesis of equal variances.\")\n",
        "      print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE NO statistically significant differences between the variance of the classifiers.\")\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "id": "oJjIxSlGewah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset_name, dataset in datasets.items():\n",
        "    levene_test(dataset, dataset_name)"
      ],
      "metadata": {
        "id": "Al6ykcN5ezKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxWzJG6G_dDu"
      },
      "source": [
        "#### Kruskal-Wallis\n",
        "As there are datasets that do not follow a normal distribution, the Kruskal-Wallis test is performed to indicate whether there is a significant difference between the models or not (for each dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqN_PpdtfTRQ"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import kruskal\n",
        "\n",
        "def kruskal_w(df_res_kappa, dataset_name):\n",
        "\n",
        "  '''H0: The performance distributions of the classifiers are equal.\n",
        "     H1: At least one classifier's performance distribution is different from the others.'''\n",
        "\n",
        "  # Kruskal-Wallis\n",
        "  h_statistic, p_value = kruskal(*[df_res_kappa[column] for column in df_res_kappa.columns])\n",
        "\n",
        "  # Results\n",
        "  print(\"Statistical F:\", h_statistic)\n",
        "  print(\"P value:\", p_value)\n",
        "\n",
        "  if p_value < 0.05:\n",
        "    print(\"Rejects the null hypothesis.\")\n",
        "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE IS at least one classifier whose performance is statistically different from the rest.\")\n",
        "\n",
        "  else:\n",
        "    print(\"Does not reject the null hypothesis.\")\n",
        "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE NO statistically significant differences in the performance of the classifiers.\")\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qha043kfJ2GZ"
      },
      "outputs": [],
      "source": [
        "for dataset_name, dataset in datasets.items():\n",
        "    kruskal_w(dataset, dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary of those datasets that show significant differences between models\n",
        "dicc_dif = {\n",
        "    \"df_res_kappa_AAC\": df_res_kappa_AAC,\n",
        "    \"df_res_kappa_DPC\": df_res_kappa_DPC,\n",
        "    \"df_res_kappa_Mix\": df_res_kappa_Mix,\n",
        "    \"df_res_kappa_DPC_FS50\": df_res_kappa_DPC_FS50,\n",
        "    \"df_res_kappa_Mix_FS50\": df_res_kappa_Mix_FS50,\n",
        "    \"df_res_kappa_DPC_FS25\": df_res_kappa_DPC_FS25,\n",
        "    \"df_res_kappa_Mix_FS25\": df_res_kappa_Mix_FS25\n",
        "}\n",
        "\n",
        "dif_datasets = {}\n",
        "for dataset_name, dataset in dicc_dif.items():\n",
        "    dif_datasets[dataset_name] = remove(dataset)"
      ],
      "metadata": {
        "id": "DiBuGqEffGEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dunn's test with Bonferroni adjustment\n",
        "It is a non-parametric test used to perform multiple comparisons between groups. It is especially useful when data do not meet the assumptions of normality and homogeneity of variances required by tests such as ANOVA and Tukey's test.\n",
        "\n",
        "It allows for multiple comparisons of data sets and to determine specifically between which pairs of groups there are significant differences."
      ],
      "metadata": {
        "id": "cJZ4seC0fR-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-posthocs"
      ],
      "metadata": {
        "id": "hR8VGLBdfzCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5jdubyxzzHH"
      },
      "outputs": [],
      "source": [
        "import scikit_posthocs as sp\n",
        "import seaborn as sns\n",
        "\n",
        "def dunn_test(dataset, dataset_name):\n",
        "    # List of classifiers\n",
        "    classifiers = dataset.columns.tolist()\n",
        "\n",
        "    # Prepare data for Dunn's test\n",
        "    # Convert each column of data into a list and label with the classifier name\n",
        "    data = []\n",
        "    for classifier in classifiers:\n",
        "        for value in dataset[classifier].values:\n",
        "            data.append((value, classifier))\n",
        "\n",
        "    # Create a DataFrame for Dunn's test\n",
        "    df = pd.DataFrame(data, columns=['Value', 'Classifier'])\n",
        "\n",
        "    # Apply Dunn's test\n",
        "    dunn_result = sp.posthoc_dunn(df, val_col='Value', group_col='Classifier', p_adjust='bonferroni')\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\033[1mResults for the dataset {dataset_name}\\033[0m\")\n",
        "    print()\n",
        "    print(dunn_result)\n",
        "    print()\n",
        "\n",
        "    # Visualize Dunn's test results with a heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(dunn_result, cmap='viridis', annot=True, cbar=True)\n",
        "    plt.title(f\"Dunn's Test for {dataset_name}\")\n",
        "    plt.xlabel(\"Classifiers\")\n",
        "    plt.ylabel(\"Classifiers\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "    print()\n",
        "\n",
        "    # Identify significantly different models\n",
        "    # Example: If 'Model_A' is significantly different from all others\n",
        "    significant_models = []\n",
        "    for classifier in classifiers:\n",
        "        if all(dunn_result.loc[classifier, classifier_other] < 0.05 for classifier_other in classifiers if classifier_other != classifier):\n",
        "            significant_models.append(classifier)\n",
        "\n",
        "    if significant_models:\n",
        "        print(f\"The model(s) significantly different from the rest: {', '.join(significant_models)}\")\n",
        "    else:\n",
        "        print(\"No model is significantly different from the rest.\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset_name, dataset in dif_datasets.items():\n",
        "    dunn_test(dataset, dataset_name)"
      ],
      "metadata": {
        "id": "g7sg67r2f9te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plecwDZvZfc7"
      },
      "source": [
        "### Statistical Analysis\n",
        "\n",
        "### For all datasets:\n",
        "\n",
        "### NB classifier\n",
        "For the comparison of all datasets, the NB classifier of each dataset is selected as there are no significant differences between classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQelCEK3c2a1"
      },
      "outputs": [],
      "source": [
        "def NB_columns(dataframes, dataframe_names):\n",
        "    NB_columns = []\n",
        "\n",
        "    for df, df_name in zip(dataframes, dataframe_names):\n",
        "        # Extract the NB column from each dataframe\n",
        "        NB_column = pd.DataFrame(df['NB'].values)\n",
        "\n",
        "        # Rename the column\n",
        "        new_name = df_name + '_NB'\n",
        "        NB_column = NB_column.rename(columns={0: new_name})\n",
        "\n",
        "        NB_columns.append(NB_column)\n",
        "\n",
        "    # Combine all columns into a single dataframe\n",
        "    combined_df = pd.concat(NB_columns, axis=1)\n",
        "\n",
        "    return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN7629CsdNHh"
      },
      "outputs": [],
      "source": [
        "# Function call\n",
        "\n",
        "kappa_all_datasets = [df_res_kappa_AAC, df_res_kappa_DPC, df_res_kappa_Mix, df_res_kappa_AAC_FS50, df_res_kappa_DPC_FS50, df_res_kappa_Mix_FS50, df_res_kappa_AAC_FS25, df_res_kappa_DPC_FS25, df_res_kappa_Mix_FS25]\n",
        "dataframe_names = ['df_res_kappa_AAC', 'df_res_kappa_DPC', 'df_res_kappa_Mix', 'df_res_kappa_AAC_FS50', 'df_res_kappa_DPC_FS50', 'df_res_kappa_Mix_FS50', 'df_res_kappa_AAC_FS25', 'df_res_kappa_DPC_FS25', 'df_res_kappa_Mix_FS25']\n",
        "\n",
        "final_df = NB_columns(kappa_all_datasets, dataframe_names)\n",
        "print(final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHp-sd7RZ3Ss"
      },
      "source": [
        "#### Normality: Shapiro-Wilk and QQ Plot:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4bd_b6PZ4tv"
      },
      "source": [
        "#### Shapiro-Wilk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NICOhSsDZfLj"
      },
      "outputs": [],
      "source": [
        "# One-dimensional array\n",
        "kappa_data = final_df.values.flatten()\n",
        "\n",
        "# Shapiro-Wilk\n",
        "statistic, p_value = shapiro(kappa_data)\n",
        "\n",
        "# Results\n",
        "print(\"Statistical:\", statistic)\n",
        "print(\"P value:\", p_value)\n",
        "print()\n",
        "\n",
        "if p_value < 0.05:\n",
        "  print(\"Shapiro-Wilk test rejects the null hypothesis.\")\n",
        "  print(\"The NB Dataset DOES NOT FOLLOWS a normal distribution.\")\n",
        "\n",
        "else:\n",
        "  print(\"Shapiro-Wilk test does not reject the null hypothesis.\")\n",
        "  print(\"The NB Dataset FOLLOWS a normal distribution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5vIjAgKfWNZ"
      },
      "source": [
        "#### QQ-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGNBrLUMZ4Py"
      },
      "outputs": [],
      "source": [
        "# Call asses_normality function\n",
        "\n",
        "assess_normality(final_df, 'NB Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtYcI9l4iTPN"
      },
      "source": [
        "#### ANOVA\n",
        "For those datasets following a normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpTFbiTQgVHT"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "def anova(df_res_kappa, dataset_name):\n",
        "\n",
        "  '''H0: The means of the classifiers are equal.\n",
        "     H1: The means of the classifiers are not equal.'''\n",
        "\n",
        "  # ANOVA\n",
        "  f_statistic, p_value = f_oneway(*[df_res_kappa[column] for column in df_res_kappa.columns])\n",
        "\n",
        "  # Results\n",
        "  print(\"Statistical F:\", f_statistic)\n",
        "  print(\"P value:\", p_value)\n",
        "\n",
        "  if p_value < 0.05:\n",
        "    print(\"Rejects the null hypothesis.\")\n",
        "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE statistically significant differences between the classifiers's means.\")\n",
        "\n",
        "  else:\n",
        "    print(\"Does not reject the null hypothesis.\")\n",
        "    print(\"For the dataset \"f\"\\033[1m{dataset_name}\\033[0m THERE ARE NO statistically significant differences between the classifiers's means.\")\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW8_hwajA3v3"
      },
      "outputs": [],
      "source": [
        "# Call anova function\n",
        "\n",
        "anova(final_df, 'NB Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyh0lEsri7sz"
      },
      "source": [
        "#### Levene's Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sqFzREbBZ6u"
      },
      "outputs": [],
      "source": [
        "# Call levene_test function\n",
        "\n",
        "levene_test(final_df, 'NB Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOP5azMj_9Z"
      },
      "source": [
        "#### Tukey's Test\n",
        "Assumes that the data are approximately normally distributed and that the variances of the groups are homogeneous.\n",
        "\n",
        "Determine whether there are significant differences between the means of classifier performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwBlbcVioUMy"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "def tukey_test(dataset, dataset_name):\n",
        "    # List of classifiers\n",
        "    classifiers = dataset.columns.tolist()\n",
        "\n",
        "    # List to store data for each classifier\n",
        "    data = [dataset[classifier].values for classifier in classifiers]\n",
        "\n",
        "    # Flatten the list of lists into a single list\n",
        "    flattened_data = np.concatenate(data)\n",
        "\n",
        "    # Create groups for each classifier\n",
        "    groups = [classifier for classifier in classifiers for _ in range(len(dataset))]\n",
        "\n",
        "    # Tukey's test\n",
        "    tukey_result = pairwise_tukeyhsd(flattened_data, groups)\n",
        "\n",
        "    # Results\n",
        "    print(\"\\033[1mResults for the dataset \"f\"{dataset_name}\\033[0m\")\n",
        "    print()\n",
        "    print(tukey_result)\n",
        "    print()\n",
        "\n",
        "    # Plot the results of Tukey's test\n",
        "    tukey_result.plot_simultaneous()\n",
        "    plt.title(f\"Tukey Test for {dataset_name}. Comparisons Among Classifiers\")\n",
        "    plt.xlabel(\"Metric Value\")\n",
        "    plt.ylabel(\"Classifiers\")\n",
        "    plt.show()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmXry5q0j_pC"
      },
      "outputs": [],
      "source": [
        "# Call tukey_test function\n",
        "tukey_test(final_df, 'DB Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCl-jj-vfOZd"
      },
      "source": [
        "## Multivariate feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1WfzqAVLOS3"
      },
      "outputs": [],
      "source": [
        "# Multivariate feature selection\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Feature selection function using RFE with Random Forest\n",
        "def FeatureSelectionWithRFE(df, label, nFeats=1):\n",
        "    if nFeats == 0:\n",
        "        print(\"\\n NO feature selection\")\n",
        "        return df\n",
        "\n",
        "    # Separating features and target variable using getDataFromDataFrame\n",
        "    Xdata, Ydata, Features = getDataFromDataFrame(df)\n",
        "\n",
        "    # Feature selection using RFE\n",
        "    print('\\n-> Multivariate Feature selection with RFE and Random Forest')\n",
        "    print('Initial columns:', list(df.columns))\n",
        "\n",
        "    # Define the Random Forest model\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Configure RFE\n",
        "    selector = RFE(estimator=rf_model, n_features_to_select=nFeats, step=1)\n",
        "\n",
        "    # Adjust the selector to the data\n",
        "    selector = selector.fit(Xdata, Ydata)\n",
        "\n",
        "    # Obtain the selected characteristics\n",
        "    SelFeatures = []\n",
        "    for i in selector.get_support(indices=True):\n",
        "        SelFeatures.append(Features[i])\n",
        "\n",
        "    # Create the new DataFrame with the selected features\n",
        "    Xdata_selected = selector.transform(Xdata)\n",
        "    df_selected = pd.DataFrame(Xdata_selected, columns=SelFeatures)\n",
        "    df_selected['Class'] = Ydata\n",
        "\n",
        "    print('Final columns:', list(df_selected.columns))\n",
        "\n",
        "    # Save the dataset with the selected characteristics\n",
        "    selectFile = dsPath + 'ds' + label + '.normFS_RFE(' + str(nFeats) + ').csv'\n",
        "    print('* Save selected features dataset:', selectFile)\n",
        "    df_selected.to_csv(selectFile, index=False)\n",
        "\n",
        "    print('Done!')\n",
        "    return df_selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1dmtimdSY6I"
      },
      "outputs": [],
      "source": [
        "# Feature selection\n",
        "\n",
        "ds_AAC_norm_RFE = FeatureSelectionWithRFE(ds_AAC_norm, \"AAC\", nFeats=20)  # ALL\n",
        "ds_DPC_norm_RFE = FeatureSelectionWithRFE(ds_DPC_norm, \"DPC\", nFeats=400)  # ALL\n",
        "ds_Mix_norm_RFE = FeatureSelectionWithRFE(ds_Mix_norm, \"Mix\", nFeats=420)  # ALL\n",
        "ds_AAC_norm_RFE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2C1yAEUQ4X2"
      },
      "outputs": [],
      "source": [
        "ds_AAC_normFS50_RFE = FeatureSelectionWithRFE(ds_AAC_norm, \"AAC\", nFeats=10)  # 50%\n",
        "ds_DPC_normFS50_RFE = FeatureSelectionWithRFE(ds_DPC_norm, \"DPC\", nFeats=200)  # 50%\n",
        "ds_Mix_normFS50_RFE = FeatureSelectionWithRFE(ds_Mix_norm, \"Mix\", nFeats=210)  # 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnGyDyMIQ6A4"
      },
      "outputs": [],
      "source": [
        "ds_AAC_normFS25_RFE = FeatureSelectionWithRFE(ds_AAC_norm, \"AAC\", nFeats=5)  # 25%\n",
        "ds_DPC_normFS25_RFE = FeatureSelectionWithRFE(ds_DPC_norm, \"DPC\", nFeats=100)  # 25%\n",
        "ds_Mix_normFS25_RFE = FeatureSelectionWithRFE(ds_Mix_norm, \"Mix\", nFeats=105)  # 25%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzbKki8QTFA3"
      },
      "outputs": [],
      "source": [
        "# ML for AAC normalized dataset with all descriptors (no feature selection)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_norm_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_AAC_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_AAC_norm_RFE, df_res_auroc, nfold, label=\"AAC_norm_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_AAC_norm_RFE, df_res_f1, nfold, label=\"AAC_norm_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_AAC_norm_RFE, df_res_kappa_AAC_RFE, nfold, label=\"AAC_norm_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_AAC_norm_RFE, df_res_recall, nfold, label=\"AAC_norm_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_AAC_norm_RFE, df_res_precision, nfold, label=\"AAC_norm_RFE\", label_y=\"Precision\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2nA5a6OTgKR"
      },
      "outputs": [],
      "source": [
        "# ML for DPC normalized dataset with all descriptors (no feature selection)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_norm_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_DPC_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_DPC_norm_RFE, df_res_auroc, nfold, label=\"DPC_norm_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_DPC_norm_RFE, df_res_f1, nfold, label=\"DPC_norm_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_DPC_norm_RFE, df_res_kappa_DPC_RFE, nfold, label=\"DPC_norm_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_DPC_norm_RFE, df_res_recall, nfold, label=\"DPC_norm_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_DPC_norm_RFE, df_res_precision, nfold, label=\"DPC_norm_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIvMofBEUgiZ"
      },
      "outputs": [],
      "source": [
        "# ML for Mix normalized dataset with all descriptors (no feature selection)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_norm_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_Mix_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_Mix_norm_RFE, df_res_auroc, nfold, label=\"Mix_norm_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_Mix_norm_RFE, df_res_f1, nfold, label=\"Mix_norm_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_Mix_norm_RFE, df_res_kappa_Mix_RFE, nfold, label=\"Mix_norm_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_Mix_norm_RFE, df_res_recall, nfold, label=\"Mix_norm_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_Mix_norm_RFE, df_res_precision, nfold, label=\"Mix_norm_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoMZO9X3UxAn"
      },
      "outputs": [],
      "source": [
        "# ML for AAC normalized dataset with selected features (50%)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS50_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS50_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_AAC_normFS50_RFE, df_res_auroc, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_AAC_normFS50_RFE, df_res_f1, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_AAC_normFS50_RFE, df_res_kappa_AAC_FS50_RFE, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_AAC_normFS50_RFE, df_res_recall, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_AAC_normFS50_RFE, df_res_precision, nfold, label=\"AAC_norm_FS50_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox3QC5NVTgZP"
      },
      "outputs": [],
      "source": [
        "# ML for DPC normalized dataset with selected features (50%)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS50_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS50_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_DPC_normFS50_RFE, df_res_auroc, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_DPC_normFS50_RFE, df_res_f1, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_DPC_normFS50_RFE, df_res_kappa_DPC_FS50_RFE, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_DPC_normFS50_RFE, df_res_recall, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_DPC_normFS50_RFE, df_res_precision, nfold, label=\"DPC_norm_FS50_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0-wmWdPVwRc"
      },
      "outputs": [],
      "source": [
        "# ML for Mix normalized dataset with selected features (50%)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS50_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS50_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_Mix_normFS50_RFE, df_res_auroc, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_Mix_normFS50_RFE, df_res_f1, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_Mix_normFS50_RFE, df_res_kappa_Mix_FS50_RFE, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_Mix_normFS50_RFE, df_res_recall, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_Mix_normFS50_RFE, df_res_precision, nfold, label=\"Mix_norm_FS50_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_i5RfwaV9xy"
      },
      "outputs": [],
      "source": [
        "# ML for AAC normalized dataset with selected features (25%)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_AAC_normFS25_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_AAC_FS25_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_AAC_normFS25_RFE, df_res_auroc, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_AAC_normFS25_RFE, df_res_f1, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_AAC_normFS25_RFE, df_res_kappa_AAC_FS25_RFE, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_AAC_normFS25_RFE, df_res_recall, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_AAC_normFS25_RFE, df_res_precision, nfold, label=\"AAC_norm_FS25_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7HCUyrFWMBk"
      },
      "outputs": [],
      "source": [
        "# ML for DPC normalized dataset with selected features (25%)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_DPC_normFS25_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_DPC_FS25_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_DPC_normFS25_RFE, df_res_auroc, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_DPC_normFS25_RFE, df_res_f1, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_DPC_normFS25_RFE, df_res_kappa_DPC_FS25_RFE, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_DPC_normFS25_RFE, df_res_recall, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_DPC_normFS25_RFE, df_res_precision, nfold, label=\"DPC_norm_FS25_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDMHoBHbWXSB"
      },
      "outputs": [],
      "source": [
        "# ML for Mix normalized dataset with selected features (25%)\n",
        "\n",
        "Xdata, Ydata, Features = getDataFromDataFrame(ds_Mix_normFS25_RFE)\n",
        "df_res_auroc, df_res_f1, df_res_kappa_Mix_FS25_RFE, df_res_recall, df_res_precision = MLOuterCV(Xdata, Ydata, nfold)\n",
        "\n",
        "# AUROC\n",
        "MLmodels(ds_Mix_normFS25_RFE, df_res_auroc, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"AUROC\")\n",
        "\n",
        "# F1_Score\n",
        "MLmodels(ds_Mix_normFS25_RFE, df_res_f1, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"F1_Score\")\n",
        "\n",
        "# Kappa_Score\n",
        "MLmodels(ds_Mix_normFS25_RFE, df_res_kappa_Mix_FS25_RFE, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"Kappa_Score\")\n",
        "\n",
        "# Recall\n",
        "MLmodels(ds_Mix_normFS25_RFE, df_res_recall, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"Recall\")\n",
        "\n",
        "# Precision\n",
        "MLmodels(ds_Mix_normFS25_RFE, df_res_precision, nfold, label=\"Mix_norm_FS25_RFE\", label_y=\"Precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BizatuYFRxiy"
      },
      "source": [
        "### Statistical Analysis\n",
        "### For each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4IL6B8RXUhK"
      },
      "outputs": [],
      "source": [
        "# Remove the last two columns from each dataframe\n",
        "\n",
        "dicc_RFE = {\n",
        "    \"df_res_kappa_AAC_RFE\": df_res_kappa_AAC_RFE,\n",
        "    \"df_res_kappa_DPC_RFE\": df_res_kappa_DPC_RFE,\n",
        "    \"df_res_kappa_Mix_RFE\": df_res_kappa_Mix_RFE,\n",
        "    \"df_res_kappa_AAC_FS50_RFE\": df_res_kappa_AAC_FS50_RFE,\n",
        "    \"df_res_kappa_DPC_FS50_RFE\": df_res_kappa_DPC_FS50_RFE,\n",
        "    \"df_res_kappa_Mix_FS50_RFE\": df_res_kappa_Mix_FS50_RFE,\n",
        "    \"df_res_kappa_AAC_FS25_RFE\": df_res_kappa_AAC_FS25_RFE,\n",
        "    \"df_res_kappa_DPC_FS25_RFE\": df_res_kappa_DPC_FS25_RFE,\n",
        "    \"df_res_kappa_Mix_FS25_RFE\": df_res_kappa_Mix_FS25_RFE\n",
        "}\n",
        "\n",
        "datasets_RFE = {}\n",
        "\n",
        "for dataset_name, dataset in dicc_RFE.items():\n",
        "    datasets_RFE[dataset_name] = remove(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm1qW5F_Za_2"
      },
      "outputs": [],
      "source": [
        "# Call Shapiro-Wilks function for each data set\n",
        "\n",
        "for dataset_name, dataset in datasets_RFE.items():\n",
        "    shapiro_test(dataset, dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH7oJ2FhZuiN"
      },
      "outputs": [],
      "source": [
        "# QQplot\n",
        "\n",
        "for dataset_name, dataset in datasets_RFE.items():\n",
        "    assess_normality(dataset, dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Levene's test\n",
        "\n",
        "for dataset_name, dataset in datasets_RFE.items():\n",
        "    levene_test(dataset, dataset_name)"
      ],
      "metadata": {
        "id": "C7I1eAbAg5Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kruskall Wallis\n",
        "\n",
        "for dataset_name, dataset in datasets_RFE.items():\n",
        "    kruskal_w(dataset, dataset_name)"
      ],
      "metadata": {
        "id": "w4x2PdTLg74b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dunn's test\n",
        "\n",
        "for dataset_name, dataset in datasets_RFE.items():\n",
        "    dunn_test(dataset, dataset_name)"
      ],
      "metadata": {
        "id": "GGQASfhhg-rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TanK_IP1SnB3"
      },
      "source": [
        "### Statistical analysis\n",
        "### For all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3DgDUBTlpi0"
      },
      "outputs": [],
      "source": [
        "kappa_all_datasets = [df_res_kappa_AAC_RFE, df_res_kappa_DPC_RFE, df_res_kappa_Mix_RFE, df_res_kappa_AAC_FS50_RFE, df_res_kappa_DPC_FS50_RFE, df_res_kappa_Mix_FS50_RFE, df_res_kappa_AAC_FS25_RFE, df_res_kappa_DPC_FS25_RFE, df_res_kappa_Mix_FS25_RFE]\n",
        "dataframe_names = ['df_res_kappa_AAC_RFE', 'df_res_kappa_DPC_RFE', 'df_res_kappa_Mix_RFE', 'df_res_kappa_AAC_FS50_RFE', 'df_res_kappa_DPC_FS50_RFE', 'df_res_kappa_Mix_FS50_RFE', 'df_res_kappa_AAC_FS25_RFE', 'df_res_kappa_DPC_FS25_RFE', 'df_res_kappa_Mix_FS25_RFE']\n",
        "\n",
        "final_df_RFE = NB_columns(kappa_all_datasets, dataframe_names)\n",
        "print(final_df_RFE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-G-qqiZmciO"
      },
      "outputs": [],
      "source": [
        "# one-dimensional array\n",
        "kappa_data = final_df_RFE.values.flatten()\n",
        "\n",
        "# Shapiro-Wilk\n",
        "statistic, p_value = shapiro(kappa_data)\n",
        "\n",
        "# results\n",
        "print(\"Statistical:\", statistic)\n",
        "print(\"P value:\", p_value)\n",
        "print()\n",
        "\n",
        "if p_value < 0.05:\n",
        "  print(\"Shapiro-Wilk test rejects the null hypothesis.\")\n",
        "  print(\"The NB Dataset DOES NOT FOLLOWS a normal distribution.\")\n",
        "\n",
        "else:\n",
        "  print(\"Shapiro-Wilk test does not reject the null hypothesis.\")\n",
        "  print(\"The NB Dataset FOLLOWS a normal distribution.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIJZquQ0mx5d"
      },
      "outputs": [],
      "source": [
        "# ANOVA\n",
        "anova(final_df_RFE, 'NB Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBa6pdGZmynb"
      },
      "outputs": [],
      "source": [
        "# Levene's test\n",
        "levene_test(final_df_RFE, 'NB Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfPKa0e2m_HY"
      },
      "outputs": [],
      "source": [
        "#Tukey's test\n",
        "tukey_test(final_df_RFE, 'DB Dataset')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "my4vKoxD9yOC",
        "WMBuSxdqI60s",
        "_ttMkSpjtGvd",
        "mgUtGT6zEKjY",
        "O-R8LqQd2K2g",
        "Rzijyjy3D60D",
        "59VJ1xDo_v62",
        "wCsSLk_kK358",
        "plecwDZvZfc7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}